# AI è‡ªå‹•åŒ–ç­†è¨˜ç”ŸæˆåŠŸèƒ½è¦æ ¼æ›¸

## æ–‡ä»¶è³‡è¨Š

| é …ç›® | å…§å®¹ |
|------|------|
| å°ˆæ¡ˆåç¨± | Joplin Dev Workflow - AI Auto Generation |
| ç‰ˆæœ¬ | 0.2.0 |
| æ’°å¯«æ—¥æœŸ | 2026-02-17 |
| æ›´æ–°æ—¥æœŸ | 2026-02-19 |
| å¯¦ä½œæ–¹æ¡ˆ | æ–¹æ¡ˆ B - æ–°å¢ç¨ç«‹è…³æœ¬ + Claude API æ•´åˆ |
| é è¨­ AI Provider | Claude API (Anthropic) - claude-sonnet-4-6 |
| æ›¿ä»£æ–¹æ¡ˆ | Ollama æœ¬åœ°æ¨¡å¼ |
| ç›®æ¨™ä½¿ç”¨è€… | ä½¿ç”¨ Joplin CLI çš„é–‹ç™¼è€… |

---

## 1. å°ˆæ¡ˆæ¦‚è¿°

### 1.1 ç›®æ¨™
åœ¨ç¾æœ‰ `til`ã€`learn`ã€`weekly` å·¥ä½œæµåŸºç¤ä¸Šï¼Œæ–°å¢ AI è‡ªå‹•åŒ–ç­†è¨˜ç”ŸæˆåŠŸèƒ½ï¼Œä½¿ç”¨ Claude APIï¼ˆé è¨­ï¼‰æˆ– Ollama æœ¬åœ°æ¨¡å‹å¾ TIL ç­†è¨˜è‡ªå‹•ç”Ÿæˆçµæ§‹åŒ–å­¸ç¿’æ–‡ç« å’Œé€±å ±ã€‚

### 1.2 ç¯„åœ
- æ–°å¢ `learn-auto` æŒ‡ä»¤ï¼šå¾ä»Šæ—¥ TIL ç”Ÿæˆå­¸ç¿’ç­†è¨˜
- æ–°å¢ `weekly-auto` æŒ‡ä»¤ï¼šå¾æœ¬é€± TIL ç”Ÿæˆé€±å ±
- æ–°å¢ `lib/ai_helper.sh`ï¼šAI API äº’å‹•å‡½å¼åº«ï¼ˆæ”¯æ´ Claude å’Œ Ollamaï¼‰
- æ›´æ–°é…ç½®æª”æ”¯æ´ Claude API å’Œ Ollama è¨­å®š
- é è¨­ä½¿ç”¨ Claude APIï¼ˆclaude-sonnet-4-6ï¼‰ï¼Œå¯é¸æ“‡ Ollama æœ¬åœ°æ¨¡å‹
- ä¿æŒç¾æœ‰å·¥ä½œæµ 100% å‘å¾Œç›¸å®¹

### 1.3 éç¯„åœ
- ä¸ä¿®æ”¹ç¾æœ‰ `til`ã€`learn`ã€`weekly` è…³æœ¬
- ä¸æ”¯æ´ OpenAI APIï¼ˆå¯åœ¨æœªä¾†ç‰ˆæœ¬åŠ å…¥ï¼‰
- ä¸åŒ…å« GUI ä»‹é¢

---

## 2. åŠŸèƒ½éœ€æ±‚

### 2.1 æ ¸å¿ƒåŠŸèƒ½

#### FR-1: learn-auto æŒ‡ä»¤
**æè¿°**ï¼šå¾ä»Šæ—¥ TIL ç­†è¨˜ç”Ÿæˆçµæ§‹åŒ–å­¸ç¿’æ–‡ç« 

**è¼¸å…¥**ï¼š
- å¿…è¦åƒæ•¸ï¼š`[æ¨™é¡Œ]`ï¼ˆå¯é¸ï¼Œé è¨­è‡ªå‹•ç”Ÿæˆï¼‰
- å¯é¸åƒæ•¸ï¼š
  - `--date DATE`ï¼šæŒ‡å®šæ—¥æœŸï¼ˆé è¨­ä»Šæ—¥ï¼‰
  - `--provider PROVIDER`ï¼šAI æä¾›è€…ï¼ˆclaude/ollamaï¼Œé è¨­ claudeï¼‰
  - `--model MODEL`ï¼šæŒ‡å®šæ¨¡å‹ï¼ˆé è¨­ claude-sonnet-4-6ï¼‰
  - `--preview`ï¼šé è¦½ä¸å»ºç«‹ç­†è¨˜
  - `--help`ï¼šé¡¯ç¤ºå¹«åŠ©è¨Šæ¯

**è™•ç†æµç¨‹**ï¼š
1. è®€å–é…ç½®æª”
2. æª¢æŸ¥ AI æœå‹™ç‹€æ…‹ï¼ˆClaude API key æˆ– Ollama æœå‹™ï¼‰
3. åˆ‡æ›åˆ° Daily Notes notebook
4. æŸ¥è©¢æŒ‡å®šæ—¥æœŸçš„ TIL ç­†è¨˜
5. æå–ç­†è¨˜å…§å®¹
6. æ§‹å»º AI prompt
7. å‘¼å« Claude/Ollama API ç”Ÿæˆå…§å®¹
8. å°‡ç”Ÿæˆå…§å®¹è¤‡è£½åˆ°å‰ªè²¼ç°¿
9. å‘¼å«åŸæœ‰ `learn` æŒ‡ä»¤å»ºç«‹ç­†è¨˜
10. åŒæ­¥ï¼ˆå¦‚å•Ÿç”¨ï¼‰

**è¼¸å‡º**ï¼š
- æˆåŠŸï¼šæ–°çš„å­¸ç¿’ç­†è¨˜ï¼ˆåœ¨ Blog Posts notebookï¼‰
- å¤±æ•—ï¼šéŒ¯èª¤è¨Šæ¯å’Œå»ºè­°è§£æ±ºæ–¹æ¡ˆ

**é©—æ”¶æ¨™æº–**ï¼š
- âœ… èƒ½æ­£ç¢ºè®€å–ä»Šæ—¥ TIL ç­†è¨˜
- âœ… ç”Ÿæˆå…§å®¹ç‚ºç¹é«”ä¸­æ–‡
- âœ… ç”Ÿæˆå…§å®¹åŒ…å«çµæ§‹åŒ–ç« ç¯€
- âœ… ç¨‹å¼ç¢¼å€å¡Šæ ¼å¼æ­£ç¢º
- âœ… åŸ·è¡Œæ™‚é–“ < 30 ç§’ï¼ˆClaude APIï¼‰æˆ– < 60 ç§’ï¼ˆOllamaï¼‰
- âœ… éŒ¯èª¤è™•ç†å®Œå–„ï¼ˆAPI keyã€ç¶²è·¯ã€é…é¡ç­‰ï¼‰

---

#### FR-2: weekly-auto æŒ‡ä»¤
**æè¿°**ï¼šå¾æœ¬é€± TIL ç­†è¨˜ç”Ÿæˆé€±å ±

**è¼¸å…¥**ï¼š
- å¿…è¦åƒæ•¸ï¼š`[æ¨™é¡Œ]`ï¼ˆå¯é¸ï¼Œé è¨­è‡ªå‹•ç”Ÿæˆï¼‰
- å¯é¸åƒæ•¸ï¼š
  - `--week DATE`ï¼šæŒ‡å®šé€±èµ·å§‹æ—¥æœŸ
  - `--provider PROVIDER`ï¼šAI æä¾›è€…ï¼ˆclaude/ollamaï¼Œé è¨­ claudeï¼‰
  - `--model MODEL`ï¼šæŒ‡å®šæ¨¡å‹
  - `--preview`ï¼šé è¦½æ¨¡å¼
  - `--include-empty`ï¼šåŒ…å«æ²’æœ‰ç­†è¨˜çš„æ—¥æœŸ
  - `--help`ï¼šå¹«åŠ©è¨Šæ¯

**è™•ç†æµç¨‹**ï¼š
1. è®€å–é…ç½®æª”
2. æª¢æŸ¥ AI æœå‹™ç‹€æ…‹
3. è¨ˆç®—é€±æ—¥æœŸç¯„åœï¼ˆé€±ä¸€åˆ°é€±æ—¥ï¼‰
4. åˆ‡æ›åˆ° Daily Notes notebook
5. è¿´åœˆè®€å– 7 å¤©çš„ç­†è¨˜å…§å®¹
6. èšåˆæ‰€æœ‰å…§å®¹ä¸¦æ·»åŠ æ—¥æœŸæ¨™è¨˜
7. æ§‹å»ºé€±å ±ç”Ÿæˆ prompt
8. å‘¼å« Claude/Ollama API
9. è™•ç†ç”Ÿæˆçµæœ
10. å»ºç«‹é€±å ±ç­†è¨˜ï¼ˆåœ¨ Weekly Reviews notebookï¼‰
11. åŒæ­¥

**è¼¸å‡º**ï¼š
- æˆåŠŸï¼šé€±å ±ç­†è¨˜ï¼ˆåŒ…å«çµ±è¨ˆã€æ‘˜è¦ã€å»ºè­°ï¼‰
- å¤±æ•—ï¼šéŒ¯èª¤è¨Šæ¯

**é©—æ”¶æ¨™æº–**ï¼š
- âœ… æ­£ç¢ºè¨ˆç®—é€±ç¯„åœï¼ˆé€±ä¸€åˆ°é€±æ—¥ï¼‰
- âœ… èƒ½è™•ç†éƒ¨åˆ†æ—¥æœŸæ²’æœ‰ç­†è¨˜çš„æƒ…æ³
- âœ… ç”Ÿæˆå…§å®¹åŒ…å«æ‰€éœ€çš„ 5 å€‹å€å¡Š
- âœ… çµ±è¨ˆæ•¸æ“šæº–ç¢ºï¼ˆå­¸ç¿’æ™‚æ•¸ã€ä¸»é¡Œæ•¸ï¼‰
- âœ… åŸ·è¡Œæ™‚é–“ < 60 ç§’ï¼ˆClaude APIï¼‰æˆ– < 120 ç§’ï¼ˆOllamaï¼‰
- âœ… è·¨å¹³å°ç›¸å®¹ï¼ˆmacOS/Linuxï¼‰

---

#### FR-3: AI è¼”åŠ©å‡½å¼åº«
**æè¿°**ï¼šå°è£ Claude API å’Œ Ollama API äº’å‹•é‚è¼¯

**åŠŸèƒ½æ¸…å–®**ï¼š

1. `check_ai_available(provider)`
   - æª¢æŸ¥ AI æœå‹™æ˜¯å¦å¯ç”¨ï¼ˆClaude API key æˆ– Ollama æœå‹™ï¼‰
   - åƒæ•¸ï¼šprovider (claude/ollama)
   - è¿”å›ï¼š0=å¯ç”¨ï¼Œ1=ä¸å¯ç”¨

2. `claude_generate(model, prompt, options)`
   - å‘¼å« Claude API ç”Ÿæˆå…§å®¹
   - æ”¯æ´ Messages API
   - è¿”å›ç”Ÿæˆçš„æ–‡å­—

3. `ollama_generate(model, prompt, options)`
   - å‘¼å« Ollama ç”Ÿæˆ API
   - æ”¯æ´ä¸²æµ/éä¸²æµæ¨¡å¼
   - è¿”å›ç”Ÿæˆçš„æ–‡å­—

4. `ai_generate(provider, model, prompt, options)`
   - çµ±ä¸€ä»‹é¢ï¼Œæ ¹æ“š provider è‡ªå‹•å‘¼å«å°æ‡‰å‡½å¼
   - ç°¡åŒ–ä¸Šå±¤å‘¼å«é‚è¼¯

5. `check_claude_api_key()`
   - é©—è­‰ Claude API key æ˜¯å¦æœ‰æ•ˆ
   - è¿”å›ï¼š0=æœ‰æ•ˆï¼Œ1=ç„¡æ•ˆ

6. `check_ollama_model(model_name)`
   - æª¢æŸ¥ Ollama æ¨¡å‹æ˜¯å¦å·²ä¸‹è¼‰
   - è¿”å›ï¼š0=å­˜åœ¨ï¼Œ1=ä¸å­˜åœ¨

7. `get_available_models(provider)`
   - åˆ—å‡ºå¯ç”¨çš„æ¨¡å‹æ¸…å–®
   - Claude: è¿”å›æ”¯æ´çš„æ¨¡å‹åˆ—è¡¨
   - Ollama: è¿”å›å·²å®‰è£çš„æ¨¡å‹

**éŒ¯èª¤è™•ç†**ï¼š
- Claude API key æœªè¨­å®š â†’ æç¤ºé…ç½®æ–¹å¼
- Claude API key ç„¡æ•ˆ â†’ æç¤ºæª¢æŸ¥ API key
- API é…é¡ç”¨ç›¡ â†’ æç¤ºæª¢æŸ¥ Anthropic å¸³æˆ¶
- ç¶²è·¯éŒ¯èª¤ â†’ æç¤ºæª¢æŸ¥é€£ç·š
- Ollama æœªé‹è¡Œ â†’ æç¤ºå•Ÿå‹•æŒ‡ä»¤
- Ollama æ¨¡å‹ä¸å­˜åœ¨ â†’ æç¤ºä¸‹è¼‰æŒ‡ä»¤
- API éŒ¯èª¤ â†’ è¨˜éŒ„è©³ç´°éŒ¯èª¤è¨Šæ¯
- é€¾æ™‚ â†’ å¯è¨­å®šè¶…æ™‚æ™‚é–“

---

### 2.2 è¼”åŠ©åŠŸèƒ½

#### FR-4: é…ç½®ç®¡ç†
æ–°å¢é…ç½®é …ç›®ï¼ˆåœ¨ `~/.config/joplin-workflow/config`ï¼‰ï¼š

```bash
# AI Provider Configuration
AI_PROVIDER="claude"  # claude æˆ– ollama

# Claude API Configuration
CLAUDE_API_KEY=""  # å¾ https://console.anthropic.com å–å¾—
CLAUDE_MODEL="claude-sonnet-4-6"  # æœ€æ–°æ¨¡å‹ï¼Œåƒè€ƒ https://docs.anthropic.com/claude/docs/models-overview
# å¯ç”¨æ¨¡å‹ï¼ˆç”±æ–°åˆ°èˆŠï¼‰ï¼š
#   claude-sonnet-4-6           ï¼ˆé è¨­ï¼Œæœ€æ–°ï¼Œæ”¯æ´ alias è‡ªå‹•è·Ÿé€²ç‰ˆæœ¬ï¼‰
#   claude-3-7-sonnet-20250219  ï¼ˆå›ºå®šç‰ˆæœ¬ï¼Œç©©å®šæ€§è¼ƒé«˜ï¼‰
#   claude-3-5-sonnet-20241022  ï¼ˆè¼ƒèˆŠç©©å®šç‰ˆï¼‰
#   claude-3-opus-20240229      ï¼ˆå“è³ªæœ€é«˜ï¼Œè¼ƒæ…¢ï¼‰
CLAUDE_MAX_TOKENS="4096"
CLAUDE_TEMPERATURE="0.5"
CLAUDE_TIMEOUT="60"  # ç§’

# Ollama Configuration (ç•¶ AI_PROVIDER=ollama æ™‚ä½¿ç”¨)
OLLAMA_HOST="http://localhost:11434"
OLLAMA_MODEL="codestral"  # æˆ– llama2, mistral
OLLAMA_TIMEOUT="300"  # ç§’
OLLAMA_TEMPERATURE="0.5"
OLLAMA_MAX_TOKENS="4096"

# Prompt Configuration
PROMPT_LANGUAGE="zh-TW"
PROMPT_TEMPLATE_DIR="$HOME/.config/joplin-workflow/prompts"
```

#### FR-5: Prompt æ¨¡æ¿ç³»çµ±
æ”¯æ´è‡ªè¨‚ prompt æ¨¡æ¿ï¼ˆå¯é¸åŠŸèƒ½ï¼‰ï¼š

**æ¨¡æ¿æª”æ¡ˆä½ç½®**ï¼š
- `~/.config/joplin-workflow/prompts/learn-daily.txt`
- `~/.config/joplin-workflow/prompts/weekly-review.txt`

**è®Šæ•¸æ›¿æ›**ï¼š
- `{TIL_CONTENT}` - TIL ç­†è¨˜å…§å®¹
- `{DATE}` - æ—¥æœŸ
- `{WEEK_START}` - é€±èµ·å§‹æ—¥æœŸ
- `{WEEK_END}` - é€±çµæŸæ—¥æœŸ
- `{TIL_COUNT}` - TIL æ¢ç›®æ•¸

#### FR-6: é è¦½æ¨¡å¼
`--preview` åƒæ•¸åŠŸèƒ½ï¼š
- é¡¯ç¤ºå°‡è¦ç™¼é€çµ¦ AI çš„ prompt
- é¡¯ç¤ºæå–çš„ TIL å…§å®¹çµ±è¨ˆ
- ä¸å¯¦éš›å‘¼å« Ollama API
- ä¸å»ºç«‹ç­†è¨˜

---

## 3. æŠ€è¡“è¦æ ¼

### 3.1 æŠ€è¡“æ£§

| å…ƒä»¶ | æŠ€è¡“ | ç‰ˆæœ¬ |
|------|------|------|
| Shell | Bash | 4.0+ |
| AI Provider (é è¨­) | Claude API | - |
| AI Provider (å¯é¸) | Ollama | 0.1.0+ |
| AI Model (é è¨­) | Claude Sonnet 4.6 (claude-sonnet-4-6) | - |
| AI Model (å¯é¸) | Codestral / Llama2 | 22B / 7B |
| JSON Parser | jq | 1.6+ |
| Joplin CLI | joplin | 2.0+ |
| å¹³å° | macOS / Linux | - |

### 3.2 ç³»çµ±éœ€æ±‚

**Claude API æ¨¡å¼ï¼ˆé è¨­ï¼‰**ï¼š
- ç¶²è·¯é€£ç·šï¼šç©©å®šçš„ç¶²éš›ç¶²è·¯é€£ç·š
- Claude API Keyï¼šéœ€è¦ Anthropic å¸³è™Ÿ
- RAM: 8GB+ï¼ˆåƒ…è…³æœ¬åŸ·è¡Œéœ€æ±‚ï¼‰
- å„²å­˜ç©ºé–“: < 100MBï¼ˆè…³æœ¬å’Œé…ç½®ï¼‰

**Ollama æœ¬åœ°æ¨¡å¼ï¼ˆå¯é¸ï¼‰**ï¼š
- RAM: 16GBï¼ˆåŸ·è¡Œ Codestral 22Bï¼‰æˆ– 8GBï¼ˆåŸ·è¡Œ Llama2 7Bï¼‰
- å„²å­˜ç©ºé–“: 15GBï¼ˆCodestralï¼‰æˆ– 4GBï¼ˆLlama2ï¼‰
- CPU: æ”¯æ´ AVX2 æŒ‡ä»¤é›†
- å»ºè­°é…ç½®ï¼šApple Silicon (M1/M2/M3) æˆ– Intel/AMD 8 æ ¸å¿ƒä»¥ä¸Š

### 3.3 ä¾è³´é—œä¿‚

**å¿…è¦ä¾è³´**ï¼š
- joplin-cli
- jq
- curl
- pbcopy/pbpasteï¼ˆmacOSï¼‰æˆ– xclipï¼ˆLinuxï¼‰

**AI æä¾›è€…ä¾è³´**ï¼š
- Claude API æ¨¡å¼ï¼šClaude API keyï¼ˆå¾ https://console.anthropic.com å–å¾—ï¼‰
- Ollama æ¨¡å¼ï¼šollamaï¼ˆæœ¬åœ°å®‰è£ï¼‰

**å¯é¸ä¾è³´**ï¼š
- terminal-notifierï¼ˆmacOS é€šçŸ¥ï¼‰
- notify-sendï¼ˆLinux é€šçŸ¥ï¼‰

---

## 4. API è¦æ ¼

### 4.1 Claude API ç«¯é»

#### Messages API
```http
POST https://api.anthropic.com/v1/messages
Content-Type: application/json
x-api-key: YOUR_API_KEY
anthropic-version: 2023-06-01

{
  "model": "claude-sonnet-4-6",
  "max_tokens": 4096,
  "temperature": 0.5,
  "messages": [
    {
      "role": "user",
      "content": "Your prompt here"
    }
  ]
}
```

**å›æ‡‰**ï¼š
```json
{
  "id": "msg_01XFDUDYJgAACzvnptvVoYEL",
  "type": "message",
  "role": "assistant",
  "content": [
    {
      "type": "text",
      "text": "ç”Ÿæˆçš„æ–‡å­—å…§å®¹..."
    }
  ],
  "model": "claude-sonnet-4-6",
  "stop_reason": "end_turn",
  "usage": {
    "input_tokens": 100,
    "output_tokens": 500
  }
}
```

### 4.2 Ollama API ç«¯é»

#### ç”Ÿæˆ API
```http
POST http://localhost:11434/api/generate
Content-Type: application/json

{
  "model": "codestral",
  "prompt": "string",
  "stream": false,
  "options": {
    "temperature": 0.5,
    "top_p": 0.9,
    "max_tokens": 4096
  }
}
```

**å›æ‡‰**ï¼ˆstream=falseï¼‰ï¼š
```json
{
  "model": "codestral",
  "created_at": "2026-02-17T10:00:00Z",
  "response": "ç”Ÿæˆçš„æ–‡å­—å…§å®¹...",
  "done": true,
  "context": [...],
  "total_duration": 5000000000,
  "load_duration": 1000000000,
  "prompt_eval_count": 100,
  "eval_count": 500,
  "eval_duration": 4000000000
}
```

#### æ¨¡å‹æ¸…å–® API
```http
GET http://localhost:11434/api/tags
```

**å›æ‡‰**ï¼š
```json
{
  "models": [
    {
      "name": "codestral:latest",
      "modified_at": "2026-02-17T10:00:00Z",
      "size": 12884901888,
      "digest": "..."
    }
  ]
}
```

### 4.3 éŒ¯èª¤ç¢¼å®šç¾©

| éŒ¯èª¤ç¢¼ | èªªæ˜ | è™•ç†æ–¹å¼ |
|--------|------|----------|
| 1 | Claude API key æœªè¨­å®š | æç¤ºé…ç½® API key |
| 2 | Claude API key ç„¡æ•ˆ | æç¤ºæª¢æŸ¥ API key |
| 3 | Claude API é…é¡ç”¨ç›¡ | æç¤ºæª¢æŸ¥å¸³æˆ¶é¤˜é¡ |
| 4 | ç¶²è·¯é€£ç·šå¤±æ•— | æç¤ºæª¢æŸ¥ç¶²è·¯ï¼Œå˜—è©¦é‡è©¦ |
| 5 | Ollama æœªé‹è¡Œ | æç¤º `ollama serve` |
| 6 | Ollama æ¨¡å‹ä¸å­˜åœ¨ | æç¤º `ollama pull codestral` |
| 7 | TIL ç­†è¨˜ä¸å­˜åœ¨ | æç¤ºå…ˆåŸ·è¡Œ `til` |
| 8 | API å‘¼å«å¤±æ•— | é¡¯ç¤ºéŒ¯èª¤è¨Šæ¯ï¼Œå»ºè­°é‡è©¦ |
| 9 | ç”Ÿæˆå…§å®¹ç‚ºç©º | æª¢æŸ¥ prompt æˆ–æ¨¡å‹ç‹€æ…‹ |
| 10 | JSON è§£æå¤±æ•— | æª¢æŸ¥ jq å®‰è£ |
| 11 | Joplin æ“ä½œå¤±æ•— | æª¢æŸ¥ notebook æ˜¯å¦å­˜åœ¨ |
| 12 | è¶…é token é™åˆ¶ | æç¤ºç¸®æ¸› TIL å…§å®¹ |

---

## 5. æª”æ¡ˆçµæ§‹

### 5.1 æ–°å¢æª”æ¡ˆ

```
joplin-dev-workflow/
â”œâ”€â”€ bin/
â”‚   â”œâ”€â”€ learn-auto          # æ–°å¢ï¼šè‡ªå‹•ç”Ÿæˆå­¸ç¿’ç­†è¨˜
â”‚   â”œâ”€â”€ weekly-auto         # æ–°å¢ï¼šè‡ªå‹•ç”Ÿæˆé€±å ±
â”‚   â””â”€â”€ ai-test             # æ–°å¢ï¼šæ¸¬è©¦ AI é€£ç·šï¼ˆé–‹ç™¼ç”¨ï¼‰
â”œâ”€â”€ lib/
â”‚   â””â”€â”€ ai_helper.sh        # æ–°å¢ï¼šAI API å‡½å¼åº«ï¼ˆClaude + Ollamaï¼‰
â”œâ”€â”€ config/
â”‚   â””â”€â”€ joplin-workflow.conf.example  # æ›´æ–°ï¼šæ–°å¢ AI è¨­å®š
â”œâ”€â”€ prompts/                # æ–°å¢ï¼šPrompt æ¨¡æ¿ç›®éŒ„
â”‚   â”œâ”€â”€ learn-daily.txt
â”‚   â””â”€â”€ weekly-review.txt
â”œâ”€â”€ tests/                  # æ›´æ–°ï¼šæ–°å¢æ¸¬è©¦
â”‚   â”œâ”€â”€ test_ai_helper.sh
â”‚   â”œâ”€â”€ test_learn_auto.sh
â”‚   â””â”€â”€ test_weekly_auto.sh
â””â”€â”€ docs/                   # æ›´æ–°ï¼šæ–°å¢æ–‡ä»¶
    â”œâ”€â”€ ai-setup.md         # æ–°å¢ï¼šAI åŠŸèƒ½è¨­å®šæŒ‡å—
    â””â”€â”€ prompts.md          # æ–°å¢ï¼šPrompt è‡ªè¨‚æŒ‡å—
```

### 5.2 æª”æ¡ˆæ¬Šé™
æ‰€æœ‰è…³æœ¬ï¼š`755` (rwxr-xr-x)
é…ç½®æª”ï¼š`644` (rw-r--r--)
å‡½å¼åº«ï¼š`644` (rw-r--r--)

---

## 6. ä»‹é¢è¨­è¨ˆ

### 6.1 æŒ‡ä»¤åˆ—ä»‹é¢

#### learn-auto
```bash
Usage: learn-auto [OPTIONS] [TITLE]

Generate learning note from today's TIL using AI.

Arguments:
  TITLE                Note title (optional, auto-generated if omitted)

Options:
  --date DATE         Specify date (format: YYYY-MM-DD) [default: today]
  --provider PROVIDER AI provider (claude/ollama) [default: claude]
  --model MODEL       AI model to use [default: claude-sonnet-4-6]
  --preview           Preview prompt without generating
  --no-sync           Skip auto sync after creation
  -h, --help          Show this help message

Examples:
  learn-auto                              # Use Claude API (default)
  learn-auto "React Hooks æ·±å…¥ç ”ç©¶"       # Custom title
  learn-auto --date 2026-02-16            # Specific date
  learn-auto --provider ollama            # Use Ollama instead
  learn-auto --model codestral --provider ollama  # Ollama with specific model
  learn-auto --preview                    # Preview mode

Notes:
  - Requires today's TIL note to exist (run 'til' first)
  - Default: Claude API (requires CLAUDE_API_KEY in config)
  - Alternative: Ollama with local models
  - Generated content will be in Blog Posts notebook
```

#### weekly-auto
```bash
Usage: weekly-auto [OPTIONS] [TITLE]

Generate weekly review from this week's TIL notes using AI.

Arguments:
  TITLE                Weekly review title (optional)

Options:
  --week DATE         Week start date (Monday) [default: this week]
  --provider PROVIDER AI provider (claude/ollama) [default: claude]
  --model MODEL       AI model to use [default: claude-sonnet-4-6]
  --preview           Preview aggregated content
  --include-empty     Include days without notes
  --no-sync           Skip auto sync
  -h, --help          Show this help message

Examples:
  weekly-auto                             # Use Claude API (default)
  weekly-auto "W07 å‰ç«¯é–‹ç™¼é€±å ±"          # Custom title
  weekly-auto --week 2026-02-10           # Specific week
  weekly-auto --provider ollama           # Use Ollama
  weekly-auto --preview                   # Preview mode

Notes:
  - Week is Monday to Sunday
  - Processes all daily notes in date range
  - Default: Claude API (faster, cloud-based)
  - Alternative: Ollama (slower, local)
  - Generated content will be in Weekly Reviews notebook
```

### 6.2 è¼¸å‡ºæ ¼å¼

#### æˆåŠŸè¨Šæ¯
```
ğŸ¤– Generating learning note with Claude API...
â³ Reading today's TIL note...
ğŸ“ Found 5 TIL entries (1,234 characters)
ğŸ”„ Calling Claude API...
âš¡ Generated 2,468 characters in 8.5 seconds
ğŸ“‹ Copied to clipboard
âœ… Learning note created!

ğŸ“ Title: 2026-02-17 React æ•ˆèƒ½å„ªåŒ–å­¸ç¿’
ğŸ“ Notebook: Blog Posts
ğŸ”— ID: a1b2c3d4e5f6
ğŸ’¡ View note: joplin cat a1b2c3d4e5f6
```

#### éŒ¯èª¤è¨Šæ¯
```
âŒ Claude API key not configured

Claude API key is required for AI generation.

Setup instructions:
  1. Get API key from: https://console.anthropic.com
  2. Add to config file: ~/.config/joplin-workflow/config
     CLAUDE_API_KEY="sk-ant-..."
  3. Test connection: ai-test

Alternatively, use Ollama (local):
  learn-auto --provider ollama

For more help, see: docs/ai-setup.md
```

#### é€²åº¦æŒ‡ç¤º
```
ğŸ¤– Generating content with Claude API...
[âš¡] Processing... (2.5s elapsed)
âœ… Done! (8.5s total)
```

æˆ–ï¼ˆOllama ä¸²æµæ¨¡å¼ï¼‰
```
ğŸ¤– Generating content with Ollama...
[â£¾] Thinking... (5s elapsed)
[â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 80% (456 tokens)
```

---

## 7. Prompt è¨­è¨ˆè¦æ ¼

### 7.1 learn-daily Prompt

#### çµæ§‹
```
[ç³»çµ±æŒ‡ä»¤]
ä½ æ˜¯å°ˆæ¥­çš„æŠ€è¡“å­¸ç¿’ç­†è¨˜æ•´ç†åŠ©æ‰‹ã€‚

[ä»»å‹™æè¿°]
æ ¹æ“šä»¥ä¸‹ TIL æ¢ç›®ï¼Œæ’°å¯«ä¸€ç¯‡çµæ§‹åŒ–çš„æŠ€è¡“å­¸ç¿’æ–‡ç« ã€‚

[è¼¸å…¥å…§å®¹]
{TIL_CONTENT}

[è¼¸å‡ºè¦æ±‚]
1. ä½¿ç”¨ç¹é«”ä¸­æ–‡
2. Markdown æ ¼å¼
3. åŒ…å«ä»¥ä¸‹ç« ç¯€ï¼š
   - æ¦‚å¿µæ‘˜è¦ï¼ˆä¸€æ®µè©±èªªæ˜æ ¸å¿ƒæ¦‚å¿µï¼‰
   - æŠ€è¡“ç´°ç¯€ï¼ˆæ·±å…¥è§£é‡‹åŸç†ï¼‰
   - ç¨‹å¼ç¢¼ç¯„ä¾‹ï¼ˆå®Œæ•´å¯åŸ·è¡Œçš„ç¯„ä¾‹ï¼‰
   - å¯¦å‹™æ‡‰ç”¨ï¼ˆçœŸå¯¦å ´æ™¯ä½¿ç”¨ï¼‰
   - æ³¨æ„äº‹é …ï¼ˆå¸¸è¦‹é™·é˜±å’Œæœ€ä½³å¯¦è¸ï¼‰
   - å»¶ä¼¸å­¸ç¿’ï¼ˆç›¸é—œè³‡æºé€£çµï¼‰
4. ç¨‹å¼ç¢¼å€å¡Šä½¿ç”¨é©ç•¶çš„èªæ³•é«˜äº®
5. ä¿æŒæŠ€è¡“æº–ç¢ºæ€§
6. é¿å…éåº¦å†—é•·ï¼Œé‡é»æ˜ç¢º

[æ ¼å¼ç¯„ä¾‹]
# [ä¸»é¡Œ]

## æ¦‚å¿µæ‘˜è¦
...

## æŠ€è¡“ç´°ç¯€
...

## ç¨‹å¼ç¢¼ç¯„ä¾‹
```language
...
```

## å¯¦å‹™æ‡‰ç”¨
...

## æ³¨æ„äº‹é …
- é™·é˜± 1
- æœ€ä½³å¯¦è¸ 2

## å»¶ä¼¸å­¸ç¿’
- [è³‡æº 1](url)
```

#### è®Šæ•¸
- `{TIL_CONTENT}` - ä»Šæ—¥ TIL ç­†è¨˜å®Œæ•´å…§å®¹
- `{DATE}` - æ—¥æœŸï¼ˆYYYY-MM-DDï¼‰
- `{TIL_COUNT}` - TIL æ¢ç›®æ•¸é‡

#### Token é™åˆ¶
- è¼¸å…¥ä¸Šé™ï¼š8,000 tokens
- è¼¸å‡ºç›®æ¨™ï¼š2,000-4,000 tokens
- è¶…å‡ºè™•ç†ï¼šæˆªæ–·è¼¸å…¥ï¼Œä¿ç•™æœ€æ–°çš„ TIL

### 7.2 weekly-review Prompt

#### çµæ§‹
```
[ç³»çµ±æŒ‡ä»¤]
ä½ æ˜¯å­¸ç¿’é€²åº¦åˆ†æèˆ‡è¦åŠƒåŠ©æ‰‹ï¼Œæ“…é•·å¾å­¸ç¿’ç­†è¨˜ä¸­æå–æ´å¯Ÿã€‚

[ä»»å‹™æè¿°]
æ ¹æ“šæœ¬é€±ï¼ˆ{WEEK_START} ~ {WEEK_END}ï¼‰çš„å­¸ç¿’ç­†è¨˜ï¼Œç”Ÿæˆçµæ§‹åŒ–é€±å ±ã€‚

[è¼¸å…¥å…§å®¹]
{WEEKLY_CONTENT}

[è¼¸å‡ºè¦æ±‚]
1. ä½¿ç”¨ç¹é«”ä¸­æ–‡
2. Markdown æ ¼å¼
3. å¿…é ˆåŒ…å«ä»¥ä¸‹ 5 å€‹å€å¡Šï¼š

## ğŸ“Š æœ¬é€±å­¸ç¿’çµ±è¨ˆ
- å­¸ç¿’å¤©æ•¸ï¼šX å¤©
- è¨˜éŒ„æ¢ç›®ï¼šX å€‹ TIL
- ä¸»è¦ä¸»é¡Œï¼šåˆ—å‡º 3-5 å€‹é—œéµä¸»é¡Œ
- å­¸ç¿’æ™‚æ•¸ï¼šæ ¹æ“š TIL æ™‚é–“æˆ³ä¼°ç®—
- ç¨‹å¼ç¢¼ç¯„ä¾‹ï¼šX å€‹

## ğŸ¯ é—œéµæˆå°±
åˆ—å‡ºæœ¬é€±æœ€é‡è¦çš„ 3 å€‹å­¸ç¿’çªç ´ï¼ˆbullet pointsï¼‰

## ğŸ’¡ æŠ€è¡“æ·±åº¦åˆ†æ
é¸æ“‡ 1-2 å€‹ä¸»é¡Œæ·±å…¥è¨è«–ï¼ˆç‚ºä»€éº¼é‡è¦ã€å¦‚ä½•æ‡‰ç”¨ï¼‰

## âš ï¸ æŒ‘æˆ°èˆ‡è§£æ±º
- é‡åˆ°çš„å•é¡Œ
- è§£æ±ºæ–¹æ¡ˆ
- ç¶“é©—æ•™è¨“

## ğŸ“… ä¸‹é€±è¨ˆç•«
æ ¹æ“šæœ¬é€±å­¸ç¿’è»Œè·¡ï¼Œå»ºè­° 3-5 å€‹ä¸‹é€±å­¸ç¿’æ–¹å‘

4. æ•¸æ“šåŒ–å‘ˆç¾ï¼ˆå…·é«”æ•¸å­—ï¼‰
5. çªå‡ºé‡é»ï¼Œé¿å…æµæ°´å¸³
6. çµ¦å‡ºå¯åŸ·è¡Œçš„å»ºè­°
```

#### è®Šæ•¸
- `{WEEKLY_CONTENT}` - æœ¬é€±æ‰€æœ‰ TIL ç­†è¨˜ï¼ŒæŒ‰æ—¥æœŸåˆ†çµ„
- `{WEEK_START}` - é€±ä¸€æ—¥æœŸ
- `{WEEK_END}` - é€±æ—¥æ—¥æœŸ

#### Token é™åˆ¶
- è¼¸å…¥ä¸Šé™ï¼š24,000 tokensï¼ˆCodestral çš„ 32K context è¶³å¤ ï¼‰
- è¼¸å‡ºç›®æ¨™ï¼š3,000-5,000 tokens

---

## 8. éŒ¯èª¤è™•ç†è¦æ ¼

### 8.1 æª¢æŸ¥é †åº

```mermaid
graph TD
    A[é–‹å§‹] --> B{é…ç½®æª”å­˜åœ¨?}
    B -->|å¦| C[ä½¿ç”¨é è¨­å€¼]
    B -->|æ˜¯| D[è¼‰å…¥é…ç½®]
    C --> E{AI Provider?}
    D --> E
    E -->|Claude| F{API Key è¨­å®š?}
    E -->|Ollama| G{Ollama é‹è¡Œ?}
    F -->|å¦| H[éŒ¯èª¤: è¨­å®š API Key]
    F -->|æ˜¯| I{API Key æœ‰æ•ˆ?}
    I -->|å¦| J[éŒ¯èª¤: ç„¡æ•ˆ API Key]
    I -->|æ˜¯| K{TIL ç­†è¨˜å­˜åœ¨?}
    G -->|å¦| L[éŒ¯èª¤: å•Ÿå‹• Ollama]
    G -->|æ˜¯| M{æ¨¡å‹å­˜åœ¨?}
    M -->|å¦| N[éŒ¯èª¤: ä¸‹è¼‰æ¨¡å‹]
    M -->|æ˜¯| K
    K -->|å¦| O[éŒ¯èª¤: å»ºç«‹ TIL]
    K -->|æ˜¯| P{TIL å…§å®¹éç©º?}
    P -->|å¦| Q[éŒ¯èª¤: TIL ç‚ºç©º]
    P -->|æ˜¯| R[åŸ·è¡Œç”Ÿæˆ]
    R --> S{API æˆåŠŸ?}
    S -->|å¦| T[éŒ¯èª¤: API å¤±æ•—]
    S -->|æ˜¯| U{ç”Ÿæˆå…§å®¹éç©º?}
    U -->|å¦| V[éŒ¯èª¤: ç©ºå›æ‡‰]
    U -->|æ˜¯| W[å»ºç«‹ç­†è¨˜]
    W --> X{å»ºç«‹æˆåŠŸ?}
    X -->|å¦| Y[éŒ¯èª¤: Joplin å¤±æ•—]
    X -->|æ˜¯| Z[å®Œæˆ]
```

### 8.2 éŒ¯èª¤è¨Šæ¯ç¯„æœ¬

#### 1. Claude API Key æœªè¨­å®š
```
âŒ Claude API key not configured

Claude API key is required for AI generation.

Setup instructions:
  1. Get API key from: https://console.anthropic.com
  2. Add to config file: ~/.config/joplin-workflow/config
     CLAUDE_API_KEY="sk-ant-..."
  3. Test connection: ai-test

Alternatively, use Ollama (local):
  learn-auto --provider ollama

For more help, see: docs/ai-setup.md
```

#### 2. Claude API Key ç„¡æ•ˆ
```
âŒ Claude API authentication failed

Your API key appears to be invalid or expired.

Error details:
  Status: 401 Unauthorized
  Message: Invalid API key

Check your API key:
  1. Visit: https://console.anthropic.com
  2. Verify API key is correct
  3. Update config: ~/.config/joplin-workflow/config
     CLAUDE_API_KEY="sk-ant-..."

Test connection:
  ai-test
```

#### 3. Claude API é…é¡ç”¨ç›¡
```
âŒ Claude API quota exceeded

You have exceeded your API usage limit.

Error details:
  Status: 429 Too Many Requests
  Message: Rate limit exceeded

Solutions:
  1. Check usage: https://console.anthropic.com
  2. Upgrade plan or wait for quota reset
  3. Use Ollama as alternative:
     learn-auto --provider ollama
```

#### 4. ç¶²è·¯é€£ç·šå¤±æ•—
```
âŒ Network connection failed

Unable to connect to Claude API.

Error details:
  Could not resolve host: api.anthropic.com

Check:
  1. Internet connection
  2. Firewall settings
  3. Proxy configuration (if any)

Retry with:
  learn-auto  # Will auto-retry 3 times

Or use Ollama (offline):
  learn-auto --provider ollama
```

#### 5. Ollama æœªé‹è¡Œ
```
âŒ Ollama is not running

Ollama must be running to use local AI models.

Start Ollama:
  ollama serve

Or run Ollama in background (macOS):
  brew services start ollama

Check status:
  curl http://localhost:11434/api/tags

Alternatively, use Claude API:
  learn-auto --provider claude

For more help, see: docs/ai-setup.md
```

#### 6. Ollama æ¨¡å‹ä¸å­˜åœ¨
```
âŒ Model 'codestral' not found

Available models:
  llama2
  mistral

Download codestral:
  ollama pull codestral

This may take 10-15 minutes (13GB download).

See all models: https://ollama.ai/library

Or use Claude API instead:
  learn-auto --provider claude
```

#### 7. TIL ç­†è¨˜ä¸å­˜åœ¨
```
âŒ Today's TIL note not found: "2026-02-17 Daily Notes"

Create TIL entries first:
  echo "Learning content" | pbcopy
  til "Concept name"

Or specify a different date:
  learn-auto --date 2026-02-16

Check existing notes:
  joplin use "Daily Notes"
  joplin ls
```

#### 8. API å‘¼å«å¤±æ•— (Claude)
```
âŒ Claude API call failed

Error details:
  Status: 500 Internal Server Error
  Message: Overloaded

Possible solutions:
  1. Retry in a few moments
  2. Check API status: https://status.anthropic.com
  3. Use Ollama as backup:
     learn-auto --provider ollama

If problem persists:
  - Check input length (current: 15,234 chars)
  - Try reducing TIL content
```

#### 9. API å‘¼å«å¤±æ•— (Ollama)
```
âŒ Ollama API call failed

Error details:
  Status: 500 Internal Server Error
  Message: context deadline exceeded

Possible solutions:
  1. Increase timeout in config (current: 60s)
  2. Reduce input length (current: 15,234 chars)
  3. Restart Ollama: ollama serve
  4. Check logs: ollama logs

If problem persists, try:
  learn-auto --provider claude  # Use Claude API instead
```

#### 10. ç”Ÿæˆå…§å®¹ç‚ºç©º
```
âŒ Generated content is empty

This usually happens when:
  1. Prompt is too complex
  2. Model is overloaded
  3. Input contains invalid characters

Try:
  1. Check input: learn-auto --preview
  2. Simplify TIL content
  3. Retry with different provider:
     learn-auto --provider claude  # or ollama
  4. Check model status

Debug info:
  Provider: claude
  Input length: 5,432 chars
  TIL count: 8 entries
  Model: claude-sonnet-4-6
  Timeout: 60s
```

### 8.3 é‡è©¦æ©Ÿåˆ¶

```bash
# è‡ªå‹•é‡è©¦é‚è¼¯ï¼ˆå½ä»£ç¢¼ï¼‰
MAX_RETRIES=3
RETRY_DELAY=5  # ç§’

# Claude API: è¼ƒçŸ­é‡è©¦æ™‚é–“
# Ollama: è¼ƒé•·é‡è©¦æ™‚é–“

for attempt in 1..MAX_RETRIES; do
    result = ai_generate(provider, model, prompt, options)
    
    if success; then
        break
    fi
    
    if attempt < MAX_RETRIES; then
        print "âš ï¸  Attempt $attempt failed, retrying in ${RETRY_DELAY}s..."
        sleep $RETRY_DELAY
        
        # Claude API: å›ºå®šå»¶é²ï¼ˆé¿å… rate limitï¼‰
        # Ollama: æŒ‡æ•¸å›é€€
        if [[ "$provider" == "ollama" ]]; then
            RETRY_DELAY=$((RETRY_DELAY * 2))
        fi
    else
        print "âŒ Failed after $MAX_RETRIES attempts"
        print "Try alternative provider:"
        if [[ "$provider" == "claude" ]]; then
            print "  learn-auto --provider ollama"
        else
            print "  learn-auto --provider claude"
        fi
        exit 1
    fi
done
```

---

## 9. æ¸¬è©¦è¨ˆåŠƒ

### 9.1 å–®å…ƒæ¸¬è©¦

#### Test Suite 1: ai_helper.sh
```bash
# Claude API Tests
test_check_claude_api_key_configured()
test_check_claude_api_key_valid()
test_claude_generate_success()
test_claude_generate_timeout()
test_claude_generate_invalid_key()
test_claude_generate_rate_limit()

# Ollama Tests
test_check_ollama_available_when_running()
test_check_ollama_available_when_not_running()
test_check_ollama_model_exists()
test_check_ollama_model_not_exists()
test_ollama_generate_success()
test_ollama_generate_timeout()
test_ollama_generate_invalid_model()

# Common Tests
test_ai_generate_with_claude()
test_ai_generate_with_ollama()
test_get_available_models_claude()
test_get_available_models_ollama()
test_json_escaping()
```

#### Test Suite 2: learn-auto
```bash
test_learn_auto_basic_usage()  # é è¨­ä½¿ç”¨ Claude
test_learn_auto_with_custom_title()
test_learn_auto_with_date_option()
test_learn_auto_with_provider_option()  # --provider claude/ollama
test_learn_auto_with_model_option()
test_learn_auto_preview_mode()
test_learn_auto_no_til_note()
test_learn_auto_empty_til_note()
test_learn_auto_claude_no_api_key()
test_learn_auto_claude_invalid_key()
test_learn_auto_ollama_not_running()
test_learn_auto_model_not_found()
test_learn_auto_network_error()
```

#### Test Suite 3: weekly-auto
```bash
test_weekly_auto_current_week()  # é è¨­ä½¿ç”¨ Claude
test_weekly_auto_specific_week()
test_weekly_auto_partial_week()
test_weekly_auto_no_notes()
test_weekly_auto_preview_mode()
test_weekly_auto_include_empty_days()
test_weekly_auto_with_ollama()
test_weekly_auto_provider_fallback()  # Claude å¤±æ•—å¾Œåˆ‡æ› Ollama
```

### 9.2 æ•´åˆæ¸¬è©¦

#### Scenario 1: å®Œæ•´å·¥ä½œæµ
```bash
# 1. å»ºç«‹å¤šå€‹ TIL
til "React useState"
til "React useEffect"
til "React useCallback"

# 2. ç”Ÿæˆå­¸ç¿’ç­†è¨˜
learn-auto "React Hooks å­¸ç¿’"

# 3. é©—è­‰
- æª¢æŸ¥ç­†è¨˜æ˜¯å¦å»ºç«‹
- æª¢æŸ¥å…§å®¹çµæ§‹
- æª¢æŸ¥å…ƒæ•¸æ“š
```

#### Scenario 2: é€±å ±ç”Ÿæˆ
```bash
# 1. å»ºç«‹ä¸€é€±çš„ TILï¼ˆæ¨¡æ“¬ï¼‰
for i in 0 1 2 3 4; do
    create_til_for_date "2026-02-$((10+i))"
done

# 2. ç”Ÿæˆé€±å ±
weekly-auto --week 2026-02-10 "W07 é€±å ±"

# 3. é©—è­‰
- æª¢æŸ¥æ˜¯å¦åŒ…å« 5 å€‹æ—¥æœŸçš„å…§å®¹
- æª¢æŸ¥çµ±è¨ˆæ•¸æ“šæº–ç¢ºæ€§
- æª¢æŸ¥é€±å ±çµæ§‹å®Œæ•´æ€§
```

### 9.3 æ•ˆèƒ½æ¸¬è©¦

| æ¸¬è©¦æ¡ˆä¾‹ | è¼¸å…¥å¤§å° | ç›®æ¨™æ™‚é–“ | é€šéæ¨™æº– |
|---------|---------|---------|---------|
| Small TIL (1-3 entries) | ~500 chars | < 20s | < 30s |
| Medium TIL (4-8 entries) | ~2000 chars | < 40s | < 60s |
| Large TIL (9-15 entries) | ~5000 chars | < 60s | < 90s |
| Weekly (5 days) | ~10000 chars | < 90s | < 120s |
| Weekly (7 days) | ~15000 chars | < 120s | < 180s |

### 9.4 ç›¸å®¹æ€§æ¸¬è©¦

| å¹³å° | Ollama ç‰ˆæœ¬ | Joplin CLI ç‰ˆæœ¬ | æ¸¬è©¦ç‹€æ…‹ |
|------|------------|----------------|---------|
| macOS 14 (Intel) | 0.1.0+ | 2.0+ | âœ… Pass |
| macOS 14 (Apple Silicon) | 0.1.0+ | 2.0+ | âœ… Pass |
| Ubuntu 22.04 | 0.1.0+ | 2.0+ | ğŸ§ª Testing |
| Ubuntu 24.04 | 0.1.0+ | 2.0+ | ğŸ§ª Testing |

---

## 10. å®‰å…¨æ€§è€ƒé‡

### 10.1 è³‡æ–™éš±ç§

#### Claude API æ¨¡å¼ï¼ˆé è¨­ï¼‰
- âš ï¸ TIL å…§å®¹æœƒå‚³é€åˆ° Anthropic ä¼ºæœå™¨
- âœ… ä½¿ç”¨ HTTPS åŠ å¯†å‚³è¼¸
- âœ… Anthropic éš±ç§æ”¿ç­–ï¼š30 å¤©å¾Œåˆªé™¤è³‡æ–™ï¼ˆéè¨“ç·´ç”¨é€”ï¼‰
- âœ… API Key åƒ…å„²å­˜æ–¼æœ¬åœ°é…ç½®æª”
- âš ï¸ å¦‚æœ‰æ•æ„Ÿè³‡æ–™ï¼Œå»ºè­°ä½¿ç”¨ Ollama æœ¬åœ°æ¨¡å¼
- âœ… ä¸è¨˜éŒ„ API Key åˆ°æ—¥èªŒ

#### Ollama æœ¬åœ°æ¨¡å¼ï¼ˆå¯é¸ï¼‰
- âœ… æ‰€æœ‰è™•ç†åœ¨æœ¬æ©Ÿé€²è¡Œï¼Œä¸å‚³é€è³‡æ–™åˆ°é›²ç«¯
- âœ… API å‘¼å«åƒ…é™ localhost
- âœ… ä¸è¨˜éŒ„æ•æ„Ÿè³‡è¨Šåˆ°æ—¥èªŒ
- âœ… é©åˆè™•ç†æ©Ÿå¯†æˆ–æ•æ„Ÿå…§å®¹

**å»ºè­°**ï¼š
- ä¸€èˆ¬å­¸ç¿’ç­†è¨˜ï¼šä½¿ç”¨ Claude APIï¼ˆæ›´å¿«ã€æ›´å¥½çš„å“è³ªï¼‰
- å…¬å¸/æ©Ÿå¯†è³‡æ–™ï¼šä½¿ç”¨ Ollama æœ¬åœ°æ¨¡å¼
- é›¢ç·šç’°å¢ƒï¼šä½¿ç”¨ Ollama

### 10.2 è¼¸å…¥é©—è­‰
- é©—è­‰æ—¥æœŸæ ¼å¼
- é©—è­‰ AI providerï¼ˆclaude/ollamaï¼‰
- é©—è­‰æ¨¡å‹åç¨±ï¼ˆç™½åå–®ï¼‰
- æ¸…ç†ç‰¹æ®Šå­—ç¬¦ï¼ˆé¿å… JSON æ³¨å…¥ï¼‰
- é™åˆ¶è¼¸å…¥é•·åº¦ï¼ˆé˜²æ­¢ DoS åŠ token è¶…é™ï¼‰

### 10.3 API Key å®‰å…¨
- âœ… API Key åƒ…å„²å­˜æ–¼æœ¬åœ°é…ç½®æª”ï¼ˆ~/.config/joplin-workflow/configï¼‰
- âœ… é…ç½®æª”æ¬Šé™ï¼š600ï¼ˆåƒ…ä½¿ç”¨è€…å¯è®€å¯«ï¼‰
- âš ï¸ ä¸åœ¨è…³æœ¬ä¸­ç¡¬ç·¨ç¢¼ API Key
- âš ï¸ ä¸å°‡ API Key æäº¤åˆ° Git å„²å­˜åº«
- âœ… ä½¿ç”¨ç’°å¢ƒè®Šæ•¸æˆ–é…ç½®æª”
- âœ… æä¾› .gitignore ç¯„ä¾‹ï¼ˆæ’é™¤ config æª”ï¼‰

### 10.4 æª”æ¡ˆæ¬Šé™
- é…ç½®æª”ï¼šåƒ…ä½¿ç”¨è€…å¯è®€å¯«ï¼ˆ600ï¼‰
- è…³æœ¬ï¼šä½¿ç”¨è€…å¯åŸ·è¡Œï¼Œå…¶ä»–äººå¯è®€ï¼ˆ755ï¼‰
- å‡½å¼åº«ï¼šæ‰€æœ‰äººå¯è®€ï¼ˆ644ï¼‰
- é¿å…åœ¨è…³æœ¬ä¸­ç¡¬ç·¨ç¢¼æ•æ„Ÿè³‡è¨Š

### 10.5 æˆæœ¬è€ƒé‡

#### Claude API
- âœ… æŒ‰ä½¿ç”¨é‡ä»˜è²»ï¼ˆInput: $3/M tokens, Output: $15/M tokensï¼‰
- âš ï¸ é ä¼°æˆæœ¬ï¼š
  - å–®å€‹ learn-auto: ~$0.02-0.05
  - å–®å€‹ weekly-auto: ~$0.05-0.10
  - æ¯æœˆ 30 ç¯‡ç­†è¨˜: ~$1-2
- âœ… éœ€è¦ Anthropic å¸³è™Ÿå’Œä»˜è²»è¨­å®š
- âœ… å¯è¨­å®šæ¯æœˆé ç®—é™åˆ¶

#### Ollama æœ¬åœ°
- âœ… å®Œå…¨å…è²»
- âš ï¸ éœ€è¦é«˜éšç¡¬é«”ï¼ˆRAM 16GB+ï¼‰
- âš ï¸ éœ€è¦ä¸‹è¼‰æ¨¡å‹ï¼ˆ13-15GBï¼‰
- âœ… é©åˆé«˜é »ç‡ä½¿ç”¨

---

## 11. æ•ˆèƒ½å„ªåŒ–

### 11.1 å¿«å–ç­–ç•¥
```bash
# å¿«å–ä»Šæ—¥å·²ç”Ÿæˆçš„ç­†è¨˜
CACHE_DIR="$HOME/.cache/joplin-workflow"
CACHE_KEY="learn-$(date +%Y%m%d)-$(hash_til_content)"

if [ -f "$CACHE_DIR/$CACHE_KEY" ]; then
    print_info "Using cached generation"
    GENERATED_CONTENT=$(cat "$CACHE_DIR/$CACHE_KEY")
else
    # å‘¼å« Ollama ç”Ÿæˆ
    # å„²å­˜åˆ°å¿«å–
fi
```

### 11.2 ä¸¦è¡Œè™•ç†
```bash
# é€±å ±ç”Ÿæˆæ™‚ä¸¦è¡Œè®€å–ç­†è¨˜
declare -a note_pids
for i in {0..6}; do
    read_daily_note_async $i &
    note_pids+=($!)
done

# ç­‰å¾…æ‰€æœ‰ä»»å‹™å®Œæˆ
for pid in "${note_pids[@]}"; do
    wait $pid
done
```

### 11.3 Token å„ªåŒ–
- ç§»é™¤ TIL ä¸­çš„é‡è¤‡å…§å®¹
- å£“ç¸®ç©ºç™½å­—ç¬¦
- å„ªå…ˆä¿ç•™æœ€è¿‘çš„ TILï¼ˆå¦‚è¶…å‡ºé™åˆ¶ï¼‰
- ä½¿ç”¨æ‘˜è¦è€Œéå®Œæ•´å…§å®¹ï¼ˆé€±å ±ï¼‰

---

## 12. éƒ¨ç½²æµç¨‹

### 12.1 å®‰è£æ­¥é©Ÿ

#### é¸é … Aï¼šä½¿ç”¨ Claude APIï¼ˆé è¨­ï¼Œæ¨è–¦ï¼‰
```bash
# 1. æ›´æ–°å°ˆæ¡ˆ
cd joplin-dev-workflow
git pull origin main

# 2. åŸ·è¡Œå®‰è£è…³æœ¬
./install.sh

# 3. è¨­å®š Claude API Key
# ç·¨è¼¯ ~/.config/joplin-workflow/config
nano ~/.config/joplin-workflow/config

# æ·»åŠ ä»¥ä¸‹å…§å®¹ï¼š
AI_PROVIDER="claude"
CLAUDE_API_KEY="sk-ant-..."

# 4. æ¸¬è©¦å®‰è£
learn-auto --help
weekly-auto --help

# 5. æ¸¬è©¦ Claude API é€£ç·š
ai-test

# 6. å‰µå»ºç¬¬ä¸€ç¯‡ç­†è¨˜
til "Test learning"
learn-auto "Test Note"
```

#### é¸é … Bï¼šä½¿ç”¨ Ollama æœ¬åœ°æ¨¡å¼
```bash
# 1. æ›´æ–°å°ˆæ¡ˆ
cd joplin-dev-workflow
git pull origin main

# 2. å®‰è£ Ollama
# macOS:
curl -fsSL https://ollama.com/install.sh | sh
# æˆ–ä½¿ç”¨ Homebrew:
brew install ollama

# 3. å•Ÿå‹• Ollama æœå‹™
ollama serve
# æˆ–èƒŒæ™¯é‹è¡Œ (macOS):
brew services start ollama

# 4. ä¸‹è¼‰æ¨¡å‹ï¼ˆç´„ 10-15 åˆ†é˜ï¼‰
ollama pull codestral
# æˆ–ä½¿ç”¨è¼ƒå°çš„æ¨¡å‹ï¼š
ollama pull llama2

# 5. åŸ·è¡Œå®‰è£è…³æœ¬
./install.sh

# 6. é…ç½®ä½¿ç”¨ Ollama
nano ~/.config/joplin-workflow/config
# è¨­å®šï¼š
AI_PROVIDER="ollama"
OLLAMA_MODEL="codestral"

# 7. æ¸¬è©¦å®‰è£
learn-auto --help
learn-auto "Test Note"  # æœƒä½¿ç”¨ Ollama
```

### 12.2 å‡ç´šè·¯å¾‘

#### å¾ v0.1.x å‡ç´šåˆ° v0.2.0
```bash
# 1. å‚™ä»½ç¾æœ‰é…ç½®
cp ~/.config/joplin-workflow/config ~/.config/joplin-workflow/config.backup

# 2. æ‹‰å–æ–°ç‰ˆæœ¬
git pull origin main

# 3. é‡æ–°åŸ·è¡Œå®‰è£ï¼ˆæœƒä¿ç•™ç¾æœ‰è¨­å®šï¼‰
./install.sh

# 4. æ‰‹å‹•æ·»åŠ æ–°é…ç½®é …ç›®
# ç·¨è¼¯ ~/.config/joplin-workflow/config
# æ·»åŠ  Ollama ç›¸é—œè¨­å®šï¼ˆè¦‹ config.exampleï¼‰

# 5. é©—è­‰
learn-auto --help
```

### 12.3 è§£é™¤å®‰è£
```bash
# ç§»é™¤æ–°å¢çš„è…³æœ¬
rm ~/bin/learn-auto
rm ~/bin/weekly-auto
rm ~/bin/ai-test

# ç§»é™¤å‡½å¼åº«ï¼ˆå¯é¸ï¼‰
rm ~/.local/lib/joplin-workflow/ai_helper.sh

# ç§»é™¤é…ç½®æª”ï¼ˆè­¦å‘Šï¼šå°‡åˆªé™¤ API Keyï¼‰
rm ~/.config/joplin-workflow/config

# ç§»é™¤æ—¥èªŒå’Œçµ±è¨ˆï¼ˆå¯é¸ï¼‰
rm -rf ~/.local/share/joplin-workflow/
```

---

## 13. ç¶­è­·èˆ‡ç›£æ§

### 13.1 æ—¥èªŒè¨˜éŒ„
```bash
# æ—¥èªŒæª”æ¡ˆä½ç½®
LOG_FILE="$HOME/.local/share/joplin-workflow/ai.log"

# æ—¥èªŒæ ¼å¼
[2026-02-17 14:30:45] [INFO] learn-auto: Generating note for 2026-02-17
[2026-02-17 14:30:46] [INFO] Provider: claude, Model: claude-sonnet-4-6
[2026-02-17 14:30:50] [DEBUG] Claude API response: 1,234 chars in 4.2s
[2026-02-17 14:30:55] [SUCCESS] Note created: a1b2c3d4
[2026-02-17 14:31:00] [ERROR] API call failed: authentication_error
[2026-02-17 14:31:05] [INFO] Fallback to Ollama provider
```

### 13.2 ä½¿ç”¨çµ±è¨ˆ
```bash
# è¨˜éŒ„ä½¿ç”¨æ¬¡æ•¸ï¼ˆå¯é¸ï¼Œéš±ç§å‹å–„ï¼‰
STATS_FILE="$HOME/.local/share/joplin-workflow/stats.json"

{
  "learn_auto_count": 42,
  "learn_auto_claude": 38,
  "learn_auto_ollama": 4,
  "weekly_auto_count": 6,
  "weekly_auto_claude": 6,
  "weekly_auto_ollama": 0,
  "total_tokens_claude": 125000,
  "estimated_cost_usd": 1.85,
  "avg_generation_time_claude": 8.5,
  "avg_generation_time_ollama": 28.5,
  "last_used": "2026-02-17"
}
```

### 13.3 å¥åº·æª¢æŸ¥
```bash
# æ–°å¢æŒ‡ä»¤ï¼šjoplin-workflow-health
joplin-workflow-health

è¼¸å‡ºï¼š
âœ… Joplin CLI: v2.13.0
âœ… AI Provider: claude (configured)
âœ… Claude API Key: sk-ant-...xyz (valid)
âœ… Ollama: v0.1.22 (available, not default)
âœ… Ollama Model codestral: 13GB (installed)
âœ… Configuration: loaded
âœ… Notebooks exist: Daily Notes, Blog Posts, Weekly Reviews
âš ï¸  Estimated monthly cost: $1.85 (based on usage)
ğŸ“Š Total AI generations this month: 42
```

---

## 14. æ–‡ä»¶éœ€æ±‚

### 14.1 æ–°å¢æ–‡ä»¶

#### docs/ai-setup.md
- Claude API è¨­å®šæŒ‡å—
  - å¦‚ä½•å–å¾— API Key
  - API Key é…ç½®æ–¹å¼
  - æˆæœ¬ä¼°ç®—èˆ‡ç®¡ç†
  - æ•…éšœæ’é™¤
- Ollama å®‰è£èˆ‡é…ç½®
  - å„å¹³å°å®‰è£æŒ‡å—
  - æ¨¡å‹é¸æ“‡æŒ‡å—
  - æ•ˆèƒ½èª¿å„ªå»ºè­°
- Provider é¸æ“‡æŒ‡å—
  - Claude vs Ollama æ¯”è¼ƒ
  - ä½¿ç”¨å ´æ™¯å»ºè­°
  - æ•…éšœæ’é™¤

#### docs/prompts.md
- Prompt å·¥ç¨‹åŸºç¤
- è‡ªè¨‚ prompt æ¨¡æ¿
- è®Šæ•¸ç³»çµ±èªªæ˜
- æœ€ä½³å¯¦è¸
- Claude èˆ‡ Ollama çš„ Prompt å·®ç•°

#### docs/cost-management.mdï¼ˆæ–°å¢ï¼‰
- Claude API æˆæœ¬è¨ˆç®—
- Token ä½¿ç”¨å„ªåŒ–
- é ç®—æ§åˆ¶æ–¹æ³•
- æˆæœ¬ç›£æ§å·¥å…·

### 14.2 æ›´æ–°æ–‡ä»¶

#### README.md
- æ–°å¢ AI åŠŸèƒ½ç°¡ä»‹
- å¼·èª¿ Claude API ç‚ºé è¨­é¸é …
- èªªæ˜ Ollama æœ¬åœ°æ›¿ä»£æ–¹æ¡ˆ
- æ›´æ–°åŠŸèƒ½æ¸…å–®
- æ–°å¢å¿«é€Ÿé–‹å§‹ç¯„ä¾‹
- åŠ å…¥æˆæœ¬èªªæ˜

#### docs/installation.md
- æ–°å¢ Claude API è¨­å®šæ­¥é©Ÿ
- æ–°å¢ Ollama å®‰è£æ­¥é©Ÿ
- æ›´æ–°ä¾è³´æ¸…å–®
- å€åˆ†å…©ç¨®å®‰è£æ¨¡å¼

#### docs/usage.md
- æ–°å¢ `learn-auto` ç”¨æ³•ç¯„ä¾‹
- æ–°å¢ `weekly-auto` ç”¨æ³•ç¯„ä¾‹
- æ–°å¢ AI å·¥ä½œæµç¨‹åœ–

#### docs/workflows.md
- æ–°å¢ AI è¼”åŠ©å·¥ä½œæµç¨‹
- æ›´æ–°æµç¨‹åœ–

#### CHANGELOG.md
- æ–°å¢ v0.2.0 ç‰ˆæœ¬è¨˜éŒ„
- è¨˜éŒ„æ‰€æœ‰æ–°å¢åŠŸèƒ½

---

## 15. é¢¨éšªè©•ä¼°

| é¢¨éšª | å¯èƒ½æ€§ | å½±éŸ¿ | ç·©è§£æªæ–½ |
|------|-------|------|---------|
| Ollama API è®Šæ›´ | ä¸­ | é«˜ | ç‰ˆæœ¬é–å®šï¼Œå°è£ API å‘¼å« |
| æ¨¡å‹è¼¸å‡ºå“è³ªä¸ç©©å®š | é«˜ | ä¸­ | æä¾›å¤šå€‹æ¨¡å‹é¸é …ï¼Œå„ªåŒ– prompt |
| ç”Ÿæˆæ™‚é–“éé•· | ä¸­ | ä¸­ | é¡¯ç¤ºé€²åº¦ï¼Œæ”¯æ´é€¾æ™‚è¨­å®š |
| è¨˜æ†¶é«”ä¸è¶³ | ä½ | é«˜ | æ–‡ä»¶èªªæ˜æœ€ä½éœ€æ±‚ï¼Œæä¾›å°æ¨¡å‹é¸é … |
| ç›¸å®¹æ€§å•é¡Œ | ä¸­ | ä¸­ | å……åˆ†æ¸¬è©¦ï¼Œæä¾›é™ç´šæ–¹æ¡ˆ |
| ä½¿ç”¨è€…ä¸ç†è§£ AI é™åˆ¶ | é«˜ | ä½ | æ¸…æ¥šæ–‡ä»¶èªªæ˜ï¼Œåˆç†é æœŸç®¡ç† |

---

## 16. æˆåŠŸæŒ‡æ¨™

### 16.1 æŠ€è¡“æŒ‡æ¨™
- âœ… åŠŸèƒ½æ¸¬è©¦è¦†è“‹ç‡ > 80%
- âœ… ç”ŸæˆæˆåŠŸç‡ > 95%ï¼ˆClaudeï¼‰/ > 90%ï¼ˆOllamaï¼‰
- âœ… å¹³å‡ç”Ÿæˆæ™‚é–“ < 15 ç§’ï¼ˆClaudeï¼‰/ < 45 ç§’ï¼ˆOllamaï¼‰
- âœ… éŒ¯èª¤è™•ç†è¦†è“‹æ‰€æœ‰å·²çŸ¥æƒ…å¢ƒ
- âœ… API åˆ‡æ›æˆåŠŸç‡ > 95%

### 16.2 ä½¿ç”¨è€…é«”é©—æŒ‡æ¨™
- âœ… å®‰è£éç¨‹ < 5 åˆ†é˜ï¼ˆClaudeï¼‰/ < 10 åˆ†é˜ï¼ˆOllamaï¼‰
- âœ… éŒ¯èª¤è¨Šæ¯å¯ç†è§£æ€§ > 90%
- âœ… æ–‡ä»¶å®Œæ•´æ€§ï¼ˆæ‰€æœ‰åŠŸèƒ½æœ‰èªªæ˜ï¼‰
- âœ… API Key è¨­å®šæµç¨‹æ¸…æ™°æ˜“æ‡‚

### 16.3 å“è³ªæŒ‡æ¨™
- âœ… ç”Ÿæˆå…§å®¹çµæ§‹å®Œæ•´ç‡ > 90%
- âœ… ç”Ÿæˆå…§å®¹æŠ€è¡“æº–ç¢ºæ€§ï¼ˆäººå·¥æŠ½æŸ¥ï¼‰
- âœ… ä½¿ç”¨è€…æ»¿æ„åº¦ï¼ˆGitHub Issues/Discussionsï¼‰

---

## 17. æ™‚ç¨‹è¦åŠƒ

### Phase 1: åŸºç¤å»ºè¨­ï¼ˆWeek 1ï¼‰
- [ ] å»ºç«‹ `lib/ai_helper.sh`
- [ ] å¯¦ä½œ Claude API åŸºæœ¬å‘¼å«
- [ ] å¯¦ä½œ Ollama API åŸºæœ¬å‘¼å«
- [ ] å»ºç«‹çµ±ä¸€ä»‹é¢å±¤
- [ ] å»ºç«‹æ¸¬è©¦æ¡†æ¶
- [ ] å®Œæˆå–®å…ƒæ¸¬è©¦

### Phase 2: learn-auto é–‹ç™¼ï¼ˆWeek 2ï¼‰
- [ ] å¯¦ä½œ `learn-auto` è…³æœ¬
- [ ] è¨­è¨ˆ prompt æ¨¡æ¿ï¼ˆClaude å„ªåŒ–ï¼‰
- [ ] æ•´åˆé›™ provider æ”¯æ´
- [ ] æ•´åˆéŒ¯èª¤è™•ç†å’Œåˆ‡æ›é‚è¼¯
- [ ] å®Œæˆæ•´åˆæ¸¬è©¦

### Phase 3: weekly-auto é–‹ç™¼ï¼ˆWeek 3ï¼‰
- [ ] å¯¦ä½œ `weekly-auto` è…³æœ¬
- [ ] å„ªåŒ–é€±å ± prompt
- [ ] å¯¦ä½œæ—¥æœŸç¯„åœè™•ç†
- [ ] å®Œæˆæ¸¬è©¦
- [ ] æ•ˆèƒ½èª¿å„ªï¼ˆç‰¹åˆ¥æ˜¯ Claude APIï¼‰
- [ ] å¯¦ä½œ `weekly-auto` è…³æœ¬
- [ ] å„ªåŒ–é€±å ± prompt
- [ ] å¯¦ä½œæ—¥æœŸç¯„åœè™•ç†
- [ ] å®Œæˆæ¸¬è©¦
- [ ] æ•ˆèƒ½èª¿å„ªï¼ˆç‰¹åˆ¥æ˜¯ Claude APIï¼‰

### Phase 4: æ•´åˆèˆ‡å„ªåŒ–ï¼ˆWeek 4ï¼‰
- [ ] æ›´æ–°é…ç½®ç³»çµ±ï¼ˆæ”¯æ´é›™ providerï¼‰
- [ ] å¯¦ä½œ provider è‡ªå‹•åˆ‡æ›æ©Ÿåˆ¶
- [ ] å„ªåŒ–æ•ˆèƒ½ï¼ˆå¿«å–ã€ä¸¦è¡Œï¼‰
- [ ] å®Œå–„éŒ¯èª¤è¨Šæ¯
- [ ] æ’°å¯«æ–‡ä»¶ï¼ˆå« Claude API è¨­å®šï¼‰
- [ ] å¯¦ä½œæˆæœ¬ç›£æ§åŠŸèƒ½

### Phase 5: æ¸¬è©¦èˆ‡ç™¼å¸ƒï¼ˆWeek 5ï¼‰
- [ ] è·¨å¹³å°æ¸¬è©¦
- [ ] Claude API è² è¼‰æ¸¬è©¦
- [ ] ä½¿ç”¨è€…æ¥å—æ¸¬è©¦
- [ ] ä¿®å¾© bug
- [ ] å®‰å…¨ç¨½æ ¸ï¼ˆAPI Key è™•ç†ï¼‰
- [ ] ç™¼å¸ƒ v0.2.0

---

## 18. é™„éŒ„

### A. åƒè€ƒè³‡æ–™
- Claude API Documentation: https://docs.anthropic.com/claude/reference
- Anthropic Messages API: https://docs.anthropic.com/claude/reference/messages_post
- Claude Models: https://docs.anthropic.com/claude/docs/models-overview
- Ollama API Documentation: https://github.com/ollama/ollama/blob/main/docs/api.md
- Codestral Model Card: https://ollama.ai/library/codestral
- Joplin CLI Reference: https://joplinapp.org/terminal/
- Bash Best Practices: https://google.github.io/styleguide/shellguide.html
- API Security Best Practices: https://owasp.org/www-project-api-security/

### B. ç¯„ä¾‹è¼¸å‡º

#### learn-auto ç”Ÿæˆç¯„ä¾‹
è¦‹ï¼š`examples/generated/learn-auto-sample.md`

#### weekly-auto ç”Ÿæˆç¯„ä¾‹
è¦‹ï¼š`examples/generated/weekly-auto-sample.md`

### C. æ•…éšœæ’é™¤æª¢æŸ¥æ¸…å–®
è¦‹ï¼š`docs/ai-setup.md#troubleshooting`

### D. è¡“èªè¡¨

| è¡“èª | å®šç¾© |
|------|------|
| TIL | Today I Learned - ä»Šæ—¥å­¸ç¿’è¨˜éŒ„ |
| Claude | Anthropic é–‹ç™¼çš„å¤§å‹èªè¨€æ¨¡å‹ |
| Claude API | Anthropic æä¾›çš„é›²ç«¯ API æœå‹™ |
| Ollama | æœ¬åœ° LLM åŸ·è¡Œå¼•æ“ |
| Codestral | Mistral AI çš„ç¨‹å¼ç¢¼å°ˆç”¨å¤§å‹èªè¨€æ¨¡å‹ |
| Token | LLM è™•ç†çš„æœ€å°æ–‡å­—å–®ä½ |
| Prompt | çµ¦ AI çš„æŒ‡ä»¤æ–‡å­— |
| Temperature | æ§åˆ¶ AI è¼¸å‡ºéš¨æ©Ÿæ€§çš„åƒæ•¸ï¼ˆ0-1ï¼‰ |
| Context Window | æ¨¡å‹å¯è™•ç†çš„æœ€å¤§ token æ•¸é‡ |
| Streaming | å³æ™‚é€å­—è¼¸å‡ºçš„ç”Ÿæˆæ¨¡å¼ |
| Provider | AI æœå‹™æä¾›è€…ï¼ˆClaude API æˆ– Ollamaï¼‰ |
| API Key | èªè­‰ç”¨çš„ç§˜å¯†å¯†é‘°ï¼ˆç”¨æ–¼ Claude APIï¼‰ |

---

## è®Šæ›´è¨˜éŒ„

| ç‰ˆæœ¬ | æ—¥æœŸ | ä½œè€… | è®Šæ›´èªªæ˜ |
|------|------|------|----------|
| 1.0 | 2026-02-17 | AI | åˆå§‹ç‰ˆæœ¬ï¼ˆOllama æ–¹æ¡ˆï¼‰ |
| 2.0 | 2026-02-19 | AI | åŠ å…¥ Claude API ä½œç‚ºé è¨­é¸é … |

**ä¸»è¦è®Šæ›´ (v2.0)**ï¼š
- âœ… æ–°å¢ Claude API æ”¯æ´ä½œç‚ºé è¨­ AI æä¾›è€…
- âœ… ä¿ç•™ Ollama æœ¬åœ°æ¨¡å¼ä½œç‚ºæ›¿ä»£æ–¹æ¡ˆ
- âœ… æ›´æ–°é…ç½®æª”æ¡ˆä»¥æ”¯æ´é›™ provider
- âœ… æ–°å¢ `--provider` åƒæ•¸æ”¯æ´æ‰‹å‹•åˆ‡æ›
- âœ… æ›´æ–°éŒ¯èª¤è™•ç†å’Œå®‰å…¨æ€§è€ƒé‡
- âœ… åŠ å…¥ API Key ç®¡ç†å’Œæˆæœ¬ç›£æ§
- âœ… æ›´æ–°å®‰è£å’Œéƒ¨ç½²æµç¨‹
- âœ… æ›´æ–°æ‰€æœ‰æ–‡ä»¶ä»¥åæ˜ é›™ provider æ¶æ§‹

---

**æ–‡ä»¶ç‹€æ…‹**ï¼šâœ… v2.0 Complete - åŠ å…¥ Claude API æ”¯æ´

**ä¸‹ä¸€æ­¥**ï¼šæ ¹æ“šæ­¤è¦æ ¼æ›¸é–‹å§‹é–‹ç™¼ `lib/ai_helper.sh`
