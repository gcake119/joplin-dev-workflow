# Ollama è‡ªå‹•åŒ–ç­†è¨˜ç”ŸæˆåŠŸèƒ½è¦æ ¼æ›¸

## æ–‡ä»¶è³‡è¨Š

| é …ç›® | å…§å®¹ |
|------|------|
| å°ˆæ¡ˆåç¨± | Joplin Dev Workflow - AI Auto Generation |
| ç‰ˆæœ¬ | 0.2.0 |
| æ’°å¯«æ—¥æœŸ | 2026-02-17 |
| å¯¦ä½œæ–¹æ¡ˆ | æ–¹æ¡ˆ B - æ–°å¢ç¨ç«‹è…³æœ¬ |
| ç›®æ¨™ä½¿ç”¨è€… | ä½¿ç”¨ Joplin CLI çš„é–‹ç™¼è€… |

---

## 1. å°ˆæ¡ˆæ¦‚è¿°

### 1.1 ç›®æ¨™
åœ¨ç¾æœ‰ `til`ã€`learn`ã€`weekly` å·¥ä½œæµåŸºç¤ä¸Šï¼Œæ–°å¢ AI è‡ªå‹•åŒ–ç­†è¨˜ç”ŸæˆåŠŸèƒ½ï¼Œä½¿ç”¨ Ollama Codestral æ¨¡å‹å¾ TIL ç­†è¨˜è‡ªå‹•ç”Ÿæˆçµæ§‹åŒ–å­¸ç¿’æ–‡ç« å’Œé€±å ±ã€‚

### 1.2 ç¯„åœ
- æ–°å¢ `learn-auto` æŒ‡ä»¤ï¼šå¾ä»Šæ—¥ TIL ç”Ÿæˆå­¸ç¿’ç­†è¨˜
- æ–°å¢ `weekly-auto` æŒ‡ä»¤ï¼šå¾æœ¬é€± TIL ç”Ÿæˆé€±å ±
- æ–°å¢ `lib/ollama_helper.sh`ï¼šOllama API äº’å‹•å‡½å¼åº«
- æ›´æ–°é…ç½®æª”æ”¯æ´ Ollama è¨­å®š
- ä¿æŒç¾æœ‰å·¥ä½œæµ 100% å‘å¾Œç›¸å®¹

### 1.3 éç¯„åœ
- ä¸ä¿®æ”¹ç¾æœ‰ `til`ã€`learn`ã€`weekly` è…³æœ¬
- ä¸æ”¯æ´é›²ç«¯ AI æœå‹™ï¼ˆOpenAIã€Claude APIï¼‰
- ä¸åŒ…å« GUI ä»‹é¢

---

## 2. åŠŸèƒ½éœ€æ±‚

### 2.1 æ ¸å¿ƒåŠŸèƒ½

#### FR-1: learn-auto æŒ‡ä»¤
**æè¿°**ï¼šå¾ä»Šæ—¥ TIL ç­†è¨˜ç”Ÿæˆçµæ§‹åŒ–å­¸ç¿’æ–‡ç« 

**è¼¸å…¥**ï¼š
- å¿…è¦åƒæ•¸ï¼š`[æ¨™é¡Œ]`ï¼ˆå¯é¸ï¼Œé è¨­è‡ªå‹•ç”Ÿæˆï¼‰
- å¯é¸åƒæ•¸ï¼š
  - `--date DATE`ï¼šæŒ‡å®šæ—¥æœŸï¼ˆé è¨­ä»Šæ—¥ï¼‰
  - `--model MODEL`ï¼šæŒ‡å®šæ¨¡å‹ï¼ˆé è¨­ codestralï¼‰
  - `--preview`ï¼šé è¦½ä¸å»ºç«‹ç­†è¨˜
  - `--help`ï¼šé¡¯ç¤ºå¹«åŠ©è¨Šæ¯

**è™•ç†æµç¨‹**ï¼š
1. è®€å–é…ç½®æª”
2. æª¢æŸ¥ Ollama æœå‹™ç‹€æ…‹
3. åˆ‡æ›åˆ° Daily Notes notebook
4. æŸ¥è©¢æŒ‡å®šæ—¥æœŸçš„ TIL ç­†è¨˜
5. æå–ç­†è¨˜å…§å®¹
6. æ§‹å»º AI prompt
7. å‘¼å« Ollama API ç”Ÿæˆå…§å®¹
8. å°‡ç”Ÿæˆå…§å®¹è¤‡è£½åˆ°å‰ªè²¼ç°¿
9. å‘¼å«åŸæœ‰ `learn` æŒ‡ä»¤å»ºç«‹ç­†è¨˜
10. åŒæ­¥ï¼ˆå¦‚å•Ÿç”¨ï¼‰

**è¼¸å‡º**ï¼š
- æˆåŠŸï¼šæ–°çš„å­¸ç¿’ç­†è¨˜ï¼ˆåœ¨ Blog Posts notebookï¼‰
- å¤±æ•—ï¼šéŒ¯èª¤è¨Šæ¯å’Œå»ºè­°è§£æ±ºæ–¹æ¡ˆ

**é©—æ”¶æ¨™æº–**ï¼š
- âœ… èƒ½æ­£ç¢ºè®€å–ä»Šæ—¥ TIL ç­†è¨˜
- âœ… ç”Ÿæˆå…§å®¹ç‚ºç¹é«”ä¸­æ–‡
- âœ… ç”Ÿæˆå…§å®¹åŒ…å«çµæ§‹åŒ–ç« ç¯€
- âœ… ç¨‹å¼ç¢¼å€å¡Šæ ¼å¼æ­£ç¢º
- âœ… åŸ·è¡Œæ™‚é–“ < 60 ç§’ï¼ˆä¸€èˆ¬æƒ…æ³ï¼‰
- âœ… éŒ¯èª¤è™•ç†å®Œå–„

---

#### FR-2: weekly-auto æŒ‡ä»¤
**æè¿°**ï¼šå¾æœ¬é€± TIL ç­†è¨˜ç”Ÿæˆé€±å ±

**è¼¸å…¥**ï¼š
- å¿…è¦åƒæ•¸ï¼š`[æ¨™é¡Œ]`ï¼ˆå¯é¸ï¼Œé è¨­è‡ªå‹•ç”Ÿæˆï¼‰
- å¯é¸åƒæ•¸ï¼š
  - `--week DATE`ï¼šæŒ‡å®šé€±èµ·å§‹æ—¥æœŸ
  - `--model MODEL`ï¼šæŒ‡å®šæ¨¡å‹
  - `--preview`ï¼šé è¦½æ¨¡å¼
  - `--include-empty`ï¼šåŒ…å«æ²’æœ‰ç­†è¨˜çš„æ—¥æœŸ
  - `--help`ï¼šå¹«åŠ©è¨Šæ¯

**è™•ç†æµç¨‹**ï¼š
1. è®€å–é…ç½®æª”
2. æª¢æŸ¥ Ollama æœå‹™
3. è¨ˆç®—é€±æ—¥æœŸç¯„åœï¼ˆé€±ä¸€åˆ°é€±æ—¥ï¼‰
4. åˆ‡æ›åˆ° Daily Notes notebook
5. è¿´åœˆè®€å– 7 å¤©çš„ç­†è¨˜å…§å®¹
6. èšåˆæ‰€æœ‰å…§å®¹ä¸¦æ·»åŠ æ—¥æœŸæ¨™è¨˜
7. æ§‹å»ºé€±å ±ç”Ÿæˆ prompt
8. å‘¼å« Ollama API
9. è™•ç†ç”Ÿæˆçµæœ
10. å»ºç«‹é€±å ±ç­†è¨˜ï¼ˆåœ¨ Weekly Reviews notebookï¼‰
11. åŒæ­¥

**è¼¸å‡º**ï¼š
- æˆåŠŸï¼šé€±å ±ç­†è¨˜ï¼ˆåŒ…å«çµ±è¨ˆã€æ‘˜è¦ã€å»ºè­°ï¼‰
- å¤±æ•—ï¼šéŒ¯èª¤è¨Šæ¯

**é©—æ”¶æ¨™æº–**ï¼š
- âœ… æ­£ç¢ºè¨ˆç®—é€±ç¯„åœï¼ˆé€±ä¸€åˆ°é€±æ—¥ï¼‰
- âœ… èƒ½è™•ç†éƒ¨åˆ†æ—¥æœŸæ²’æœ‰ç­†è¨˜çš„æƒ…æ³
- âœ… ç”Ÿæˆå…§å®¹åŒ…å«æ‰€éœ€çš„ 5 å€‹å€å¡Š
- âœ… çµ±è¨ˆæ•¸æ“šæº–ç¢ºï¼ˆå­¸ç¿’æ™‚æ•¸ã€ä¸»é¡Œæ•¸ï¼‰
- âœ… åŸ·è¡Œæ™‚é–“ < 120 ç§’
- âœ… è·¨å¹³å°ç›¸å®¹ï¼ˆmacOS/Linuxï¼‰

---

#### FR-3: Ollama è¼”åŠ©å‡½å¼åº«
**æè¿°**ï¼šå°è£ Ollama API äº’å‹•é‚è¼¯

**åŠŸèƒ½æ¸…å–®**ï¼š

1. `check_ollama_available()`
   - æª¢æŸ¥ Ollama æœå‹™æ˜¯å¦é‹è¡Œ
   - è¿”å›ï¼š0=å¯ç”¨ï¼Œ1=ä¸å¯ç”¨

2. `check_ollama_model(model_name)`
   - æª¢æŸ¥æŒ‡å®šæ¨¡å‹æ˜¯å¦å·²ä¸‹è¼‰
   - è¿”å›ï¼š0=å­˜åœ¨ï¼Œ1=ä¸å­˜åœ¨

3. `ollama_generate(model, prompt, options)`
   - å‘¼å«ç”Ÿæˆ API
   - æ”¯æ´ä¸²æµ/éä¸²æµæ¨¡å¼
   - è¿”å›ç”Ÿæˆçš„æ–‡å­—

4. `ollama_generate_stream(model, prompt)`
   - ä¸²æµæ¨¡å¼ç”Ÿæˆï¼ˆå³æ™‚è¼¸å‡ºï¼‰
   - é¡¯ç¤ºç”Ÿæˆé€²åº¦

5. `get_ollama_models()`
   - åˆ—å‡ºå·²å®‰è£çš„æ¨¡å‹æ¸…å–®
   - è¿”å›æ¨¡å‹åç¨±é™£åˆ—

**éŒ¯èª¤è™•ç†**ï¼š
- Ollama æœªé‹è¡Œ â†’ æç¤ºå•Ÿå‹•æŒ‡ä»¤
- æ¨¡å‹ä¸å­˜åœ¨ â†’ æç¤ºä¸‹è¼‰æŒ‡ä»¤
- API éŒ¯èª¤ â†’ è¨˜éŒ„è©³ç´°éŒ¯èª¤è¨Šæ¯
- é€¾æ™‚ â†’ å¯è¨­å®šè¶…æ™‚æ™‚é–“

---

### 2.2 è¼”åŠ©åŠŸèƒ½

#### FR-4: é…ç½®ç®¡ç†
æ–°å¢é…ç½®é …ç›®ï¼ˆåœ¨ `~/.config/joplin-workflow/config`ï¼‰ï¼š

```bash
# Ollama Configuration
OLLAMA_HOST="http://localhost:11434"
OLLAMA_MODEL="codestral"
OLLAMA_TIMEOUT="300"  # ç§’
OLLAMA_TEMPERATURE="0.5"
OLLAMA_MAX_TOKENS="4096"

# Prompt Configuration
PROMPT_LANGUAGE="zh-TW"
PROMPT_TEMPLATE_DIR="$HOME/.config/joplin-workflow/prompts"
```

#### FR-5: Prompt æ¨¡æ¿ç³»çµ±
æ”¯æ´è‡ªè¨‚ prompt æ¨¡æ¿ï¼ˆå¯é¸åŠŸèƒ½ï¼‰ï¼š

**æ¨¡æ¿æª”æ¡ˆä½ç½®**ï¼š
- `~/.config/joplin-workflow/prompts/learn-daily.txt`
- `~/.config/joplin-workflow/prompts/weekly-review.txt`

**è®Šæ•¸æ›¿æ›**ï¼š
- `{TIL_CONTENT}` - TIL ç­†è¨˜å…§å®¹
- `{DATE}` - æ—¥æœŸ
- `{WEEK_START}` - é€±èµ·å§‹æ—¥æœŸ
- `{WEEK_END}` - é€±çµæŸæ—¥æœŸ
- `{TIL_COUNT}` - TIL æ¢ç›®æ•¸

#### FR-6: é è¦½æ¨¡å¼
`--preview` åƒæ•¸åŠŸèƒ½ï¼š
- é¡¯ç¤ºå°‡è¦ç™¼é€çµ¦ AI çš„ prompt
- é¡¯ç¤ºæå–çš„ TIL å…§å®¹çµ±è¨ˆ
- ä¸å¯¦éš›å‘¼å« Ollama API
- ä¸å»ºç«‹ç­†è¨˜

---

## 3. æŠ€è¡“è¦æ ¼

### 3.1 æŠ€è¡“æ£§

| å…ƒä»¶ | æŠ€è¡“ | ç‰ˆæœ¬ |
|------|------|------|
| Shell | Bash | 4.0+ |
| AI Runtime | Ollama | 0.1.0+ |
| AI Model | Codestral | 22B |
| JSON Parser | jq | 1.6+ |
| Joplin CLI | joplin | 2.0+ |
| å¹³å° | macOS / Linux | - |

### 3.2 ç³»çµ±éœ€æ±‚

**æœ€ä½éœ€æ±‚**ï¼š
- RAM: 16GBï¼ˆåŸ·è¡Œ Codestral 22Bï¼‰
- å„²å­˜ç©ºé–“: 15GBï¼ˆæ¨¡å‹æª”æ¡ˆï¼‰
- CPU: æ”¯æ´ AVX2 æŒ‡ä»¤é›†

**å»ºè­°é…ç½®**ï¼š
- RAM: 32GB
- CPU: Apple Silicon (M1/M2/M3) æˆ– Intel/AMD 8 æ ¸å¿ƒä»¥ä¸Š

### 3.3 ä¾è³´é—œä¿‚

**å¿…è¦ä¾è³´**ï¼š
- joplin-cli
- ollama
- jq
- curl
- pbcopy/pbpasteï¼ˆmacOSï¼‰æˆ– xclipï¼ˆLinuxï¼‰

**å¯é¸ä¾è³´**ï¼š
- terminal-notifierï¼ˆmacOS é€šçŸ¥ï¼‰
- notify-sendï¼ˆLinux é€šçŸ¥ï¼‰

---

## 4. API è¦æ ¼

### 4.1 Ollama API ç«¯é»

#### ç”Ÿæˆ API
```http
POST http://localhost:11434/api/generate
Content-Type: application/json

{
  "model": "codestral",
  "prompt": "string",
  "stream": false,
  "options": {
    "temperature": 0.5,
    "top_p": 0.9,
    "max_tokens": 4096
  }
}
```

**å›æ‡‰**ï¼ˆstream=falseï¼‰ï¼š
```json
{
  "model": "codestral",
  "created_at": "2026-02-17T10:00:00Z",
  "response": "ç”Ÿæˆçš„æ–‡å­—å…§å®¹...",
  "done": true,
  "context": [...],
  "total_duration": 5000000000,
  "load_duration": 1000000000,
  "prompt_eval_count": 100,
  "eval_count": 500,
  "eval_duration": 4000000000
}
```

#### æ¨¡å‹æ¸…å–® API
```http
GET http://localhost:11434/api/tags
```

**å›æ‡‰**ï¼š
```json
{
  "models": [
    {
      "name": "codestral:latest",
      "modified_at": "2026-02-17T10:00:00Z",
      "size": 12884901888,
      "digest": "..."
    }
  ]
}
```

### 4.2 éŒ¯èª¤ç¢¼å®šç¾©

| éŒ¯èª¤ç¢¼ | èªªæ˜ | è™•ç†æ–¹å¼ |
|--------|------|----------|
| 1 | Ollama æœªé‹è¡Œ | æç¤º `ollama serve` |
| 2 | æ¨¡å‹ä¸å­˜åœ¨ | æç¤º `ollama pull codestral` |
| 3 | TIL ç­†è¨˜ä¸å­˜åœ¨ | æç¤ºå…ˆåŸ·è¡Œ `til` |
| 4 | API å‘¼å«å¤±æ•— | é¡¯ç¤ºéŒ¯èª¤è¨Šæ¯ï¼Œå»ºè­°é‡è©¦ |
| 5 | ç”Ÿæˆå…§å®¹ç‚ºç©º | æª¢æŸ¥ prompt æˆ–æ¨¡å‹ç‹€æ…‹ |
| 6 | JSON è§£æå¤±æ•— | æª¢æŸ¥ jq å®‰è£ |
| 7 | Joplin æ“ä½œå¤±æ•— | æª¢æŸ¥ notebook æ˜¯å¦å­˜åœ¨ |

---

## 5. æª”æ¡ˆçµæ§‹

### 5.1 æ–°å¢æª”æ¡ˆ

```
joplin-dev-workflow/
â”œâ”€â”€ bin/
â”‚   â”œâ”€â”€ learn-auto          # æ–°å¢ï¼šè‡ªå‹•ç”Ÿæˆå­¸ç¿’ç­†è¨˜
â”‚   â”œâ”€â”€ weekly-auto         # æ–°å¢ï¼šè‡ªå‹•ç”Ÿæˆé€±å ±
â”‚   â””â”€â”€ ollama-test         # æ–°å¢ï¼šæ¸¬è©¦ Ollama é€£ç·šï¼ˆé–‹ç™¼ç”¨ï¼‰
â”œâ”€â”€ lib/
â”‚   â””â”€â”€ ollama_helper.sh    # æ–°å¢ï¼šOllama API å‡½å¼åº«
â”œâ”€â”€ config/
â”‚   â””â”€â”€ joplin-workflow.conf.example  # æ›´æ–°ï¼šæ–°å¢ Ollama è¨­å®š
â”œâ”€â”€ prompts/                # æ–°å¢ï¼šPrompt æ¨¡æ¿ç›®éŒ„
â”‚   â”œâ”€â”€ learn-daily.txt
â”‚   â””â”€â”€ weekly-review.txt
â”œâ”€â”€ tests/                  # æ›´æ–°ï¼šæ–°å¢æ¸¬è©¦
â”‚   â”œâ”€â”€ test_ollama_helper.sh
â”‚   â”œâ”€â”€ test_learn_auto.sh
â”‚   â””â”€â”€ test_weekly_auto.sh
â””â”€â”€ docs/                   # æ›´æ–°ï¼šæ–°å¢æ–‡ä»¶
    â”œâ”€â”€ ai-setup.md         # æ–°å¢ï¼šAI åŠŸèƒ½è¨­å®šæŒ‡å—
    â””â”€â”€ prompts.md          # æ–°å¢ï¼šPrompt è‡ªè¨‚æŒ‡å—
```

### 5.2 æª”æ¡ˆæ¬Šé™
æ‰€æœ‰è…³æœ¬ï¼š`755` (rwxr-xr-x)
é…ç½®æª”ï¼š`644` (rw-r--r--)
å‡½å¼åº«ï¼š`644` (rw-r--r--)

---

## 6. ä»‹é¢è¨­è¨ˆ

### 6.1 æŒ‡ä»¤åˆ—ä»‹é¢

#### learn-auto
```bash
Usage: learn-auto [OPTIONS] [TITLE]

Generate learning note from today's TIL using AI.

Arguments:
  TITLE                Note title (optional, auto-generated if omitted)

Options:
  --date DATE         Specify date (format: YYYY-MM-DD) [default: today]
  --model MODEL       AI model to use [default: codestral]
  --preview           Preview prompt without generating
  --no-sync           Skip auto sync after creation
  -h, --help          Show this help message

Examples:
  learn-auto                              # Auto title
  learn-auto "React Hooks æ·±å…¥ç ”ç©¶"       # Custom title
  learn-auto --date 2026-02-16            # Specific date
  learn-auto --preview                    # Preview mode

Notes:
  - Requires today's TIL note to exist (run 'til' first)
  - Requires Ollama with codestral model
  - Generated content will be in Blog Posts notebook
```

#### weekly-auto
```bash
Usage: weekly-auto [OPTIONS] [TITLE]

Generate weekly review from this week's TIL notes using AI.

Arguments:
  TITLE                Weekly review title (optional)

Options:
  --week DATE         Week start date (Monday) [default: this week]
  --model MODEL       AI model to use [default: codestral]
  --preview           Preview aggregated content
  --include-empty     Include days without notes
  --no-sync           Skip auto sync
  -h, --help          Show this help message

Examples:
  weekly-auto                             # Auto title
  weekly-auto "W07 å‰ç«¯é–‹ç™¼é€±å ±"          # Custom title
  weekly-auto --week 2026-02-10           # Specific week
  weekly-auto --preview                   # Preview mode

Notes:
  - Week is Monday to Sunday
  - Processes all daily notes in date range
  - Generated content will be in Weekly Reviews notebook
```

### 6.2 è¼¸å‡ºæ ¼å¼

#### æˆåŠŸè¨Šæ¯
```
ğŸ¤– Generating learning note with Ollama Codestral...
â³ Reading today's TIL note...
ğŸ“ Found 5 TIL entries (1,234 characters)
ğŸ”„ Calling Ollama API...
âš¡ Generated 2,468 characters in 23.5 seconds
ğŸ“‹ Copied to clipboard
âœ… Learning note created!

ğŸ“ Title: 2026-02-17 React æ•ˆèƒ½å„ªåŒ–å­¸ç¿’
ğŸ“ Notebook: Blog Posts
ğŸ”— ID: a1b2c3d4e5f6
ğŸ’¡ View note: joplin cat a1b2c3d4e5f6
```

#### éŒ¯èª¤è¨Šæ¯
```
âŒ Today's TIL note not found

Please create TIL entries first:
  til "Your learning concept"
  
Or specify a different date:
  learn-auto --date 2026-02-16
```

#### é€²åº¦æŒ‡ç¤ºï¼ˆä¸²æµæ¨¡å¼ï¼‰
```
ğŸ¤– Generating content...
[â£¾] Thinking... (5s elapsed)
[â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 80% (456 tokens)
```

---

## 7. Prompt è¨­è¨ˆè¦æ ¼

### 7.1 learn-daily Prompt

#### çµæ§‹
```
[ç³»çµ±æŒ‡ä»¤]
ä½ æ˜¯å°ˆæ¥­çš„æŠ€è¡“å­¸ç¿’ç­†è¨˜æ•´ç†åŠ©æ‰‹ã€‚

[ä»»å‹™æè¿°]
æ ¹æ“šä»¥ä¸‹ TIL æ¢ç›®ï¼Œæ’°å¯«ä¸€ç¯‡çµæ§‹åŒ–çš„æŠ€è¡“å­¸ç¿’æ–‡ç« ã€‚

[è¼¸å…¥å…§å®¹]
{TIL_CONTENT}

[è¼¸å‡ºè¦æ±‚]
1. ä½¿ç”¨ç¹é«”ä¸­æ–‡
2. Markdown æ ¼å¼
3. åŒ…å«ä»¥ä¸‹ç« ç¯€ï¼š
   - æ¦‚å¿µæ‘˜è¦ï¼ˆä¸€æ®µè©±èªªæ˜æ ¸å¿ƒæ¦‚å¿µï¼‰
   - æŠ€è¡“ç´°ç¯€ï¼ˆæ·±å…¥è§£é‡‹åŸç†ï¼‰
   - ç¨‹å¼ç¢¼ç¯„ä¾‹ï¼ˆå®Œæ•´å¯åŸ·è¡Œçš„ç¯„ä¾‹ï¼‰
   - å¯¦å‹™æ‡‰ç”¨ï¼ˆçœŸå¯¦å ´æ™¯ä½¿ç”¨ï¼‰
   - æ³¨æ„äº‹é …ï¼ˆå¸¸è¦‹é™·é˜±å’Œæœ€ä½³å¯¦è¸ï¼‰
   - å»¶ä¼¸å­¸ç¿’ï¼ˆç›¸é—œè³‡æºé€£çµï¼‰
4. ç¨‹å¼ç¢¼å€å¡Šä½¿ç”¨é©ç•¶çš„èªæ³•é«˜äº®
5. ä¿æŒæŠ€è¡“æº–ç¢ºæ€§
6. é¿å…éåº¦å†—é•·ï¼Œé‡é»æ˜ç¢º

[æ ¼å¼ç¯„ä¾‹]
# [ä¸»é¡Œ]

## æ¦‚å¿µæ‘˜è¦
...

## æŠ€è¡“ç´°ç¯€
...

## ç¨‹å¼ç¢¼ç¯„ä¾‹
```language
...
```

## å¯¦å‹™æ‡‰ç”¨
...

## æ³¨æ„äº‹é …
- é™·é˜± 1
- æœ€ä½³å¯¦è¸ 2

## å»¶ä¼¸å­¸ç¿’
- [è³‡æº 1](url)
```

#### è®Šæ•¸
- `{TIL_CONTENT}` - ä»Šæ—¥ TIL ç­†è¨˜å®Œæ•´å…§å®¹
- `{DATE}` - æ—¥æœŸï¼ˆYYYY-MM-DDï¼‰
- `{TIL_COUNT}` - TIL æ¢ç›®æ•¸é‡

#### Token é™åˆ¶
- è¼¸å…¥ä¸Šé™ï¼š8,000 tokens
- è¼¸å‡ºç›®æ¨™ï¼š2,000-4,000 tokens
- è¶…å‡ºè™•ç†ï¼šæˆªæ–·è¼¸å…¥ï¼Œä¿ç•™æœ€æ–°çš„ TIL

### 7.2 weekly-review Prompt

#### çµæ§‹
```
[ç³»çµ±æŒ‡ä»¤]
ä½ æ˜¯å­¸ç¿’é€²åº¦åˆ†æèˆ‡è¦åŠƒåŠ©æ‰‹ï¼Œæ“…é•·å¾å­¸ç¿’ç­†è¨˜ä¸­æå–æ´å¯Ÿã€‚

[ä»»å‹™æè¿°]
æ ¹æ“šæœ¬é€±ï¼ˆ{WEEK_START} ~ {WEEK_END}ï¼‰çš„å­¸ç¿’ç­†è¨˜ï¼Œç”Ÿæˆçµæ§‹åŒ–é€±å ±ã€‚

[è¼¸å…¥å…§å®¹]
{WEEKLY_CONTENT}

[è¼¸å‡ºè¦æ±‚]
1. ä½¿ç”¨ç¹é«”ä¸­æ–‡
2. Markdown æ ¼å¼
3. å¿…é ˆåŒ…å«ä»¥ä¸‹ 5 å€‹å€å¡Šï¼š

## ğŸ“Š æœ¬é€±å­¸ç¿’çµ±è¨ˆ
- å­¸ç¿’å¤©æ•¸ï¼šX å¤©
- è¨˜éŒ„æ¢ç›®ï¼šX å€‹ TIL
- ä¸»è¦ä¸»é¡Œï¼šåˆ—å‡º 3-5 å€‹é—œéµä¸»é¡Œ
- å­¸ç¿’æ™‚æ•¸ï¼šæ ¹æ“š TIL æ™‚é–“æˆ³ä¼°ç®—
- ç¨‹å¼ç¢¼ç¯„ä¾‹ï¼šX å€‹

## ğŸ¯ é—œéµæˆå°±
åˆ—å‡ºæœ¬é€±æœ€é‡è¦çš„ 3 å€‹å­¸ç¿’çªç ´ï¼ˆbullet pointsï¼‰

## ğŸ’¡ æŠ€è¡“æ·±åº¦åˆ†æ
é¸æ“‡ 1-2 å€‹ä¸»é¡Œæ·±å…¥è¨è«–ï¼ˆç‚ºä»€éº¼é‡è¦ã€å¦‚ä½•æ‡‰ç”¨ï¼‰

## âš ï¸ æŒ‘æˆ°èˆ‡è§£æ±º
- é‡åˆ°çš„å•é¡Œ
- è§£æ±ºæ–¹æ¡ˆ
- ç¶“é©—æ•™è¨“

## ğŸ“… ä¸‹é€±è¨ˆç•«
æ ¹æ“šæœ¬é€±å­¸ç¿’è»Œè·¡ï¼Œå»ºè­° 3-5 å€‹ä¸‹é€±å­¸ç¿’æ–¹å‘

4. æ•¸æ“šåŒ–å‘ˆç¾ï¼ˆå…·é«”æ•¸å­—ï¼‰
5. çªå‡ºé‡é»ï¼Œé¿å…æµæ°´å¸³
6. çµ¦å‡ºå¯åŸ·è¡Œçš„å»ºè­°
```

#### è®Šæ•¸
- `{WEEKLY_CONTENT}` - æœ¬é€±æ‰€æœ‰ TIL ç­†è¨˜ï¼ŒæŒ‰æ—¥æœŸåˆ†çµ„
- `{WEEK_START}` - é€±ä¸€æ—¥æœŸ
- `{WEEK_END}` - é€±æ—¥æ—¥æœŸ

#### Token é™åˆ¶
- è¼¸å…¥ä¸Šé™ï¼š24,000 tokensï¼ˆCodestral çš„ 32K context è¶³å¤ ï¼‰
- è¼¸å‡ºç›®æ¨™ï¼š3,000-5,000 tokens

---

## 8. éŒ¯èª¤è™•ç†è¦æ ¼

### 8.1 æª¢æŸ¥é †åº

```mermaid
graph TD
    A[é–‹å§‹] --> B{é…ç½®æª”å­˜åœ¨?}
    B -->|å¦| C[ä½¿ç”¨é è¨­å€¼]
    B -->|æ˜¯| D[è¼‰å…¥é…ç½®]
    C --> E{Ollama é‹è¡Œ?}
    D --> E
    E -->|å¦| F[éŒ¯èª¤: å•Ÿå‹• Ollama]
    E -->|æ˜¯| G{æ¨¡å‹å­˜åœ¨?}
    G -->|å¦| H[éŒ¯èª¤: ä¸‹è¼‰æ¨¡å‹]
    G -->|æ˜¯| I{TIL ç­†è¨˜å­˜åœ¨?}
    I -->|å¦| J[éŒ¯èª¤: å»ºç«‹ TIL]
    I -->|æ˜¯| K{TIL å…§å®¹éç©º?}
    K -->|å¦| L[éŒ¯èª¤: TIL ç‚ºç©º]
    K -->|æ˜¯| M[åŸ·è¡Œç”Ÿæˆ]
    M --> N{API æˆåŠŸ?}
    N -->|å¦| O[éŒ¯èª¤: API å¤±æ•—]
    N -->|æ˜¯| P{ç”Ÿæˆå…§å®¹éç©º?}
    P -->|å¦| Q[éŒ¯èª¤: ç©ºå›æ‡‰]
    P -->|æ˜¯| R[å»ºç«‹ç­†è¨˜]
    R --> S{å»ºç«‹æˆåŠŸ?}
    S -->|å¦| T[éŒ¯èª¤: Joplin å¤±æ•—]
    S -->|æ˜¯| U[å®Œæˆ]
```

### 8.2 éŒ¯èª¤è¨Šæ¯ç¯„æœ¬

#### 1. Ollama æœªé‹è¡Œ
```
âŒ Ollama is not running

Ollama must be running to use AI generation features.

Start Ollama:
  ollama serve

Or run Ollama in background (macOS):
  brew services start ollama

Check status:
  curl http://localhost:11434/api/tags

For more help, see: docs/ai-setup.md
```

#### 2. æ¨¡å‹ä¸å­˜åœ¨
```
âŒ Model 'codestral' not found

Available models:
  llama2
  mistral

Download codestral:
  ollama pull codestral

This may take 10-15 minutes (13GB download).

See all models: https://ollama.ai/library
```

#### 3. TIL ç­†è¨˜ä¸å­˜åœ¨
```
âŒ Today's TIL note not found: "2026-02-17 Daily Notes"

Create TIL entries first:
  echo "Learning content" | pbcopy
  til "Concept name"

Or specify a different date:
  learn-auto --date 2026-02-16

Check existing notes:
  joplin use "Daily Notes"
  joplin ls
```

#### 4. API å‘¼å«å¤±æ•—
```
âŒ Ollama API call failed

Error details:
  Status: 500 Internal Server Error
  Message: context deadline exceeded

Possible solutions:
  1. Increase timeout in config (current: 60s)
  2. Reduce input length (current: 15,234 chars)
  3. Restart Ollama: ollama serve
  4. Check logs: ollama logs

If problem persists, try:
  learn-auto --model llama2  # Use smaller model
```

#### 5. ç”Ÿæˆå…§å®¹ç‚ºç©º
```
âŒ Generated content is empty

This usually happens when:
  1. Prompt is too complex
  2. Model is overloaded
  3. Input contains invalid characters

Try:
  1. Check input: learn-auto --preview
  2. Simplify TIL content
  3. Retry with: learn-auto --model llama2
  4. Restart Ollama

Debug info:
  Input length: 5,432 chars
  TIL count: 8 entries
  Model: codestral
  Timeout: 60s
```

### 8.3 é‡è©¦æ©Ÿåˆ¶

```bash
# è‡ªå‹•é‡è©¦é‚è¼¯ï¼ˆå½ä»£ç¢¼ï¼‰
MAX_RETRIES=3
RETRY_DELAY=5  # ç§’

for attempt in 1..MAX_RETRIES; do
    result = ollama_generate(...)
    
    if success; then
        break
    fi
    
    if attempt < MAX_RETRIES; then
        print "âš ï¸  Attempt $attempt failed, retrying in ${RETRY_DELAY}s..."
        sleep $RETRY_DELAY
        RETRY_DELAY = RETRY_DELAY * 2  # æŒ‡æ•¸å›é€€
    else
        print "âŒ Failed after $MAX_RETRIES attempts"
        exit 1
    fi
done
```

---

## 9. æ¸¬è©¦è¨ˆåŠƒ

### 9.1 å–®å…ƒæ¸¬è©¦

#### Test Suite 1: ollama_helper.sh
```bash
test_check_ollama_available_when_running()
test_check_ollama_available_when_not_running()
test_check_ollama_model_exists()
test_check_ollama_model_not_exists()
test_ollama_generate_success()
test_ollama_generate_timeout()
test_ollama_generate_invalid_model()
test_get_ollama_models_list()
test_json_escaping()
```

#### Test Suite 2: learn-auto
```bash
test_learn_auto_basic_usage()
test_learn_auto_with_custom_title()
test_learn_auto_with_date_option()
test_learn_auto_with_model_option()
test_learn_auto_preview_mode()
test_learn_auto_no_til_note()
test_learn_auto_empty_til_note()
test_learn_auto_ollama_not_running()
test_learn_auto_model_not_found()
```

#### Test Suite 3: weekly-auto
```bash
test_weekly_auto_current_week()
test_weekly_auto_specific_week()
test_weekly_auto_partial_week()
test_weekly_auto_no_notes()
test_weekly_auto_preview_mode()
test_weekly_auto_include_empty_days()
```

### 9.2 æ•´åˆæ¸¬è©¦

#### Scenario 1: å®Œæ•´å·¥ä½œæµ
```bash
# 1. å»ºç«‹å¤šå€‹ TIL
til "React useState"
til "React useEffect"
til "React useCallback"

# 2. ç”Ÿæˆå­¸ç¿’ç­†è¨˜
learn-auto "React Hooks å­¸ç¿’"

# 3. é©—è­‰
- æª¢æŸ¥ç­†è¨˜æ˜¯å¦å»ºç«‹
- æª¢æŸ¥å…§å®¹çµæ§‹
- æª¢æŸ¥å…ƒæ•¸æ“š
```

#### Scenario 2: é€±å ±ç”Ÿæˆ
```bash
# 1. å»ºç«‹ä¸€é€±çš„ TILï¼ˆæ¨¡æ“¬ï¼‰
for i in 0 1 2 3 4; do
    create_til_for_date "2026-02-$((10+i))"
done

# 2. ç”Ÿæˆé€±å ±
weekly-auto --week 2026-02-10 "W07 é€±å ±"

# 3. é©—è­‰
- æª¢æŸ¥æ˜¯å¦åŒ…å« 5 å€‹æ—¥æœŸçš„å…§å®¹
- æª¢æŸ¥çµ±è¨ˆæ•¸æ“šæº–ç¢ºæ€§
- æª¢æŸ¥é€±å ±çµæ§‹å®Œæ•´æ€§
```

### 9.3 æ•ˆèƒ½æ¸¬è©¦

| æ¸¬è©¦æ¡ˆä¾‹ | è¼¸å…¥å¤§å° | ç›®æ¨™æ™‚é–“ | é€šéæ¨™æº– |
|---------|---------|---------|---------|
| Small TIL (1-3 entries) | ~500 chars | < 20s | < 30s |
| Medium TIL (4-8 entries) | ~2000 chars | < 40s | < 60s |
| Large TIL (9-15 entries) | ~5000 chars | < 60s | < 90s |
| Weekly (5 days) | ~10000 chars | < 90s | < 120s |
| Weekly (7 days) | ~15000 chars | < 120s | < 180s |

### 9.4 ç›¸å®¹æ€§æ¸¬è©¦

| å¹³å° | Ollama ç‰ˆæœ¬ | Joplin CLI ç‰ˆæœ¬ | æ¸¬è©¦ç‹€æ…‹ |
|------|------------|----------------|---------|
| macOS 14 (Intel) | 0.1.0+ | 2.0+ | âœ… Pass |
| macOS 14 (Apple Silicon) | 0.1.0+ | 2.0+ | âœ… Pass |
| Ubuntu 22.04 | 0.1.0+ | 2.0+ | ğŸ§ª Testing |
| Ubuntu 24.04 | 0.1.0+ | 2.0+ | ğŸ§ª Testing |

---

## 10. å®‰å…¨æ€§è€ƒé‡

### 10.1 è³‡æ–™éš±ç§
- âœ… æ‰€æœ‰è™•ç†åœ¨æœ¬æ©Ÿé€²è¡Œï¼Œä¸å‚³é€è³‡æ–™åˆ°é›²ç«¯
- âœ… API å‘¼å«åƒ…é™ localhost
- âœ… ä¸è¨˜éŒ„æ•æ„Ÿè³‡è¨Šåˆ°æ—¥èªŒ

### 10.2 è¼¸å…¥é©—è­‰
- é©—è­‰æ—¥æœŸæ ¼å¼
- é©—è­‰æ¨¡å‹åç¨±ï¼ˆç™½åå–®ï¼‰
- æ¸…ç†ç‰¹æ®Šå­—ç¬¦ï¼ˆé¿å… JSON æ³¨å…¥ï¼‰
- é™åˆ¶è¼¸å…¥é•·åº¦ï¼ˆé˜²æ­¢ DoSï¼‰

### 10.3 æª”æ¡ˆæ¬Šé™
- é…ç½®æª”ï¼šåƒ…ä½¿ç”¨è€…å¯è®€å¯«ï¼ˆ600ï¼‰
- è…³æœ¬ï¼šä½¿ç”¨è€…å¯åŸ·è¡Œï¼Œå…¶ä»–äººå¯è®€ï¼ˆ755ï¼‰
- é¿å…åœ¨è…³æœ¬ä¸­ç¡¬ç·¨ç¢¼æ•æ„Ÿè³‡è¨Š

---

## 11. æ•ˆèƒ½å„ªåŒ–

### 11.1 å¿«å–ç­–ç•¥
```bash
# å¿«å–ä»Šæ—¥å·²ç”Ÿæˆçš„ç­†è¨˜
CACHE_DIR="$HOME/.cache/joplin-workflow"
CACHE_KEY="learn-$(date +%Y%m%d)-$(hash_til_content)"

if [ -f "$CACHE_DIR/$CACHE_KEY" ]; then
    print_info "Using cached generation"
    GENERATED_CONTENT=$(cat "$CACHE_DIR/$CACHE_KEY")
else
    # å‘¼å« Ollama ç”Ÿæˆ
    # å„²å­˜åˆ°å¿«å–
fi
```

### 11.2 ä¸¦è¡Œè™•ç†
```bash
# é€±å ±ç”Ÿæˆæ™‚ä¸¦è¡Œè®€å–ç­†è¨˜
declare -a note_pids
for i in {0..6}; do
    read_daily_note_async $i &
    note_pids+=($!)
done

# ç­‰å¾…æ‰€æœ‰ä»»å‹™å®Œæˆ
for pid in "${note_pids[@]}"; do
    wait $pid
done
```

### 11.3 Token å„ªåŒ–
- ç§»é™¤ TIL ä¸­çš„é‡è¤‡å…§å®¹
- å£“ç¸®ç©ºç™½å­—ç¬¦
- å„ªå…ˆä¿ç•™æœ€è¿‘çš„ TILï¼ˆå¦‚è¶…å‡ºé™åˆ¶ï¼‰
- ä½¿ç”¨æ‘˜è¦è€Œéå®Œæ•´å…§å®¹ï¼ˆé€±å ±ï¼‰

---

## 12. éƒ¨ç½²æµç¨‹

### 12.1 å®‰è£æ­¥é©Ÿ

```bash
# 1. æ›´æ–°å°ˆæ¡ˆ
cd joplin-dev-workflow
git pull origin main

# 2. åŸ·è¡Œå®‰è£è…³æœ¬ï¼ˆè‡ªå‹•æª¢æ¸¬ Ollamaï¼‰
./install.sh

# 3. ä¸‹è¼‰ AI æ¨¡å‹ï¼ˆå¦‚éœ€è¦ï¼‰
ollama pull codestral

# 4. æ¸¬è©¦å®‰è£
learn-auto --help
weekly-auto --help

# 5. åŸ·è¡Œæ¸¬è©¦ï¼ˆå¯é¸ï¼‰
./tests/test_ollama_helper.sh
```

### 12.2 å‡ç´šè·¯å¾‘

#### å¾ v0.1.x å‡ç´šåˆ° v0.2.0
```bash
# 1. å‚™ä»½ç¾æœ‰é…ç½®
cp ~/.config/joplin-workflow/config ~/.config/joplin-workflow/config.backup

# 2. æ‹‰å–æ–°ç‰ˆæœ¬
git pull origin main

# 3. é‡æ–°åŸ·è¡Œå®‰è£ï¼ˆæœƒä¿ç•™ç¾æœ‰è¨­å®šï¼‰
./install.sh

# 4. æ‰‹å‹•æ·»åŠ æ–°é…ç½®é …ç›®
# ç·¨è¼¯ ~/.config/joplin-workflow/config
# æ·»åŠ  Ollama ç›¸é—œè¨­å®šï¼ˆè¦‹ config.exampleï¼‰

# 5. é©—è­‰
learn-auto --help
```

### 12.3 è§£é™¤å®‰è£
```bash
# ç§»é™¤æ–°å¢çš„è…³æœ¬
rm ~/bin/learn-auto
rm ~/bin/weekly-auto

# ç§»é™¤å‡½å¼åº«ï¼ˆå¯é¸ï¼‰
rm ~/.local/lib/joplin-workflow/ollama_helper.sh

# ä¿ç•™é…ç½®æª”ï¼ˆä½¿ç”¨è€…æ±ºå®šæ˜¯å¦åˆªé™¤ï¼‰
```

---

## 13. ç¶­è­·èˆ‡ç›£æ§

### 13.1 æ—¥èªŒè¨˜éŒ„
```bash
# æ—¥èªŒæª”æ¡ˆä½ç½®
LOG_FILE="$HOME/.local/share/joplin-workflow/ollama.log"

# æ—¥èªŒæ ¼å¼
[2026-02-17 14:30:45] [INFO] learn-auto: Generating note for 2026-02-17
[2026-02-17 14:30:50] [DEBUG] Ollama response: 1,234 chars in 5.2s
[2026-02-17 14:30:55] [SUCCESS] Note created: a1b2c3d4
[2026-02-17 14:31:00] [ERROR] API call failed: timeout after 60s
```

### 13.2 ä½¿ç”¨çµ±è¨ˆ
```bash
# è¨˜éŒ„ä½¿ç”¨æ¬¡æ•¸ï¼ˆå¯é¸ï¼Œéš±ç§å‹å–„ï¼‰
STATS_FILE="$HOME/.local/share/joplin-workflow/stats.json"

{
  "learn_auto_count": 42,
  "weekly_auto_count": 6,
  "total_tokens_generated": 125000,
  "avg_generation_time": 28.5,
  "last_used": "2026-02-17"
}
```

### 13.3 å¥åº·æª¢æŸ¥
```bash
# æ–°å¢æŒ‡ä»¤ï¼šjoplin-workflow-health
joplin-workflow-health

è¼¸å‡ºï¼š
âœ… Joplin CLI: v2.13.0
âœ… Ollama: v0.1.22 (running)
âœ… Model codestral: 13GB (installed)
âœ… Configuration: loaded
âœ… Notebooks exist: Daily Notes, Blog Posts, Weekly Reviews
âš ï¸  Disk space: 5GB remaining (model cache)
```

---

## 14. æ–‡ä»¶éœ€æ±‚

### 14.1 æ–°å¢æ–‡ä»¶

#### docs/ai-setup.md
- Ollama å®‰è£èˆ‡é…ç½®
- æ¨¡å‹é¸æ“‡æŒ‡å—
- æ•…éšœæ’é™¤
- æ•ˆèƒ½èª¿å„ªå»ºè­°

#### docs/prompts.md
- Prompt å·¥ç¨‹åŸºç¤
- è‡ªè¨‚ prompt æ¨¡æ¿
- è®Šæ•¸ç³»çµ±èªªæ˜
- æœ€ä½³å¯¦è¸

### 14.2 æ›´æ–°æ–‡ä»¶

#### README.md
- æ–°å¢ AI åŠŸèƒ½ç°¡ä»‹
- æ›´æ–°åŠŸèƒ½æ¸…å–®
- æ–°å¢å¿«é€Ÿé–‹å§‹ç¯„ä¾‹

#### docs/installation.md
- æ–°å¢ Ollama å®‰è£æ­¥é©Ÿ
- æ›´æ–°ä¾è³´æ¸…å–®

#### docs/usage.md
- æ–°å¢ `learn-auto` ç”¨æ³•ç¯„ä¾‹
- æ–°å¢ `weekly-auto` ç”¨æ³•ç¯„ä¾‹
- æ–°å¢ AI å·¥ä½œæµç¨‹åœ–

#### docs/workflows.md
- æ–°å¢ AI è¼”åŠ©å·¥ä½œæµç¨‹
- æ›´æ–°æµç¨‹åœ–

#### CHANGELOG.md
- æ–°å¢ v0.2.0 ç‰ˆæœ¬è¨˜éŒ„
- è¨˜éŒ„æ‰€æœ‰æ–°å¢åŠŸèƒ½

---

## 15. é¢¨éšªè©•ä¼°

| é¢¨éšª | å¯èƒ½æ€§ | å½±éŸ¿ | ç·©è§£æªæ–½ |
|------|-------|------|---------|
| Ollama API è®Šæ›´ | ä¸­ | é«˜ | ç‰ˆæœ¬é–å®šï¼Œå°è£ API å‘¼å« |
| æ¨¡å‹è¼¸å‡ºå“è³ªä¸ç©©å®š | é«˜ | ä¸­ | æä¾›å¤šå€‹æ¨¡å‹é¸é …ï¼Œå„ªåŒ– prompt |
| ç”Ÿæˆæ™‚é–“éé•· | ä¸­ | ä¸­ | é¡¯ç¤ºé€²åº¦ï¼Œæ”¯æ´é€¾æ™‚è¨­å®š |
| è¨˜æ†¶é«”ä¸è¶³ | ä½ | é«˜ | æ–‡ä»¶èªªæ˜æœ€ä½éœ€æ±‚ï¼Œæä¾›å°æ¨¡å‹é¸é … |
| ç›¸å®¹æ€§å•é¡Œ | ä¸­ | ä¸­ | å……åˆ†æ¸¬è©¦ï¼Œæä¾›é™ç´šæ–¹æ¡ˆ |
| ä½¿ç”¨è€…ä¸ç†è§£ AI é™åˆ¶ | é«˜ | ä½ | æ¸…æ¥šæ–‡ä»¶èªªæ˜ï¼Œåˆç†é æœŸç®¡ç† |

---

## 16. æˆåŠŸæŒ‡æ¨™

### 16.1 æŠ€è¡“æŒ‡æ¨™
- âœ… åŠŸèƒ½æ¸¬è©¦è¦†è“‹ç‡ > 80%
- âœ… ç”ŸæˆæˆåŠŸç‡ > 95%
- âœ… å¹³å‡ç”Ÿæˆæ™‚é–“ < 45 ç§’
- âœ… éŒ¯èª¤è™•ç†è¦†è“‹æ‰€æœ‰å·²çŸ¥æƒ…å¢ƒ

### 16.2 ä½¿ç”¨è€…é«”é©—æŒ‡æ¨™
- âœ… å®‰è£éç¨‹ < 10 åˆ†é˜
- âœ… éŒ¯èª¤è¨Šæ¯å¯ç†è§£æ€§ > 90%
- âœ… æ–‡ä»¶å®Œæ•´æ€§ï¼ˆæ‰€æœ‰åŠŸèƒ½æœ‰èªªæ˜ï¼‰

### 16.3 å“è³ªæŒ‡æ¨™
- âœ… ç”Ÿæˆå…§å®¹çµæ§‹å®Œæ•´ç‡ > 90%
- âœ… ç”Ÿæˆå…§å®¹æŠ€è¡“æº–ç¢ºæ€§ï¼ˆäººå·¥æŠ½æŸ¥ï¼‰
- âœ… ä½¿ç”¨è€…æ»¿æ„åº¦ï¼ˆGitHub Issues/Discussionsï¼‰

---

## 17. æ™‚ç¨‹è¦åŠƒ

### Phase 1: åŸºç¤å»ºè¨­ï¼ˆWeek 1ï¼‰
- [ ] å»ºç«‹ `lib/ollama_helper.sh`
- [ ] å¯¦ä½œ Ollama API åŸºæœ¬å‘¼å«
- [ ] å»ºç«‹æ¸¬è©¦æ¡†æ¶
- [ ] å®Œæˆå–®å…ƒæ¸¬è©¦

### Phase 2: learn-auto é–‹ç™¼ï¼ˆWeek 2ï¼‰
- [ ] å¯¦ä½œ `learn-auto` è…³æœ¬
- [ ] è¨­è¨ˆ prompt æ¨¡æ¿
- [ ] æ•´åˆéŒ¯èª¤è™•ç†
- [ ] å®Œæˆæ•´åˆæ¸¬è©¦

### Phase 3: weekly-auto é–‹ç™¼ï¼ˆWeek 3ï¼‰
- [ ] å¯¦ä½œ `weekly-auto` è…³æœ¬
- [ ] å„ªåŒ–é€±å ± prompt
- [ ] å¯¦ä½œæ—¥æœŸç¯„åœè™•ç†
- [ ] å®Œæˆæ¸¬è©¦

### Phase 4: æ•´åˆèˆ‡å„ªåŒ–ï¼ˆWeek 4ï¼‰
- [ ] æ›´æ–°é…ç½®ç³»çµ±
- [ ] å„ªåŒ–æ•ˆèƒ½ï¼ˆå¿«å–ã€ä¸¦è¡Œï¼‰
- [ ] å®Œå–„éŒ¯èª¤è¨Šæ¯
- [ ] æ’°å¯«æ–‡ä»¶

### Phase 5: æ¸¬è©¦èˆ‡ç™¼å¸ƒï¼ˆWeek 5ï¼‰
- [ ] è·¨å¹³å°æ¸¬è©¦
- [ ] ä½¿ç”¨è€…æ¥å—æ¸¬è©¦
- [ ] ä¿®å¾© bug
- [ ] ç™¼å¸ƒ v0.2.0

---

## 18. é™„éŒ„

### A. åƒè€ƒè³‡æ–™
- Ollama API Documentation: https://github.com/ollama/ollama/blob/main/docs/api.md
- Codestral Model Card: https://ollama.ai/library/codestral
- Joplin CLI Reference: https://joplinapp.org/terminal/
- Bash Best Practices: https://google.github.io/styleguide/shellguide.html

### B. ç¯„ä¾‹è¼¸å‡º

#### learn-auto ç”Ÿæˆç¯„ä¾‹
è¦‹ï¼š`examples/generated/learn-auto-sample.md`

#### weekly-auto ç”Ÿæˆç¯„ä¾‹
è¦‹ï¼š`examples/generated/weekly-auto-sample.md`

### C. æ•…éšœæ’é™¤æª¢æŸ¥æ¸…å–®
è¦‹ï¼š`docs/ai-setup.md#troubleshooting`

### D. è¡“èªè¡¨

| è¡“èª | å®šç¾© |
|------|------|
| TIL | Today I Learned - ä»Šæ—¥å­¸ç¿’è¨˜éŒ„ |
| Ollama | æœ¬åœ° LLM åŸ·è¡Œå¼•æ“ |
| Codestral | Mistral AI çš„ç¨‹å¼ç¢¼å°ˆç”¨å¤§å‹èªè¨€æ¨¡å‹ |
| Token | LLM è™•ç†çš„æœ€å°æ–‡å­—å–®ä½ |
| Prompt | çµ¦ AI çš„æŒ‡ä»¤æ–‡å­— |
| Temperature | æ§åˆ¶ AI è¼¸å‡ºéš¨æ©Ÿæ€§çš„åƒæ•¸ï¼ˆ0-1ï¼‰ |
| Context Window | æ¨¡å‹å¯è™•ç†çš„æœ€å¤§ token æ•¸é‡ |
| Streaming | å³æ™‚é€å­—è¼¸å‡ºçš„ç”Ÿæˆæ¨¡å¼ |

---

## è®Šæ›´è¨˜éŒ„

| ç‰ˆæœ¬ | æ—¥æœŸ | ä½œè€… | è®Šæ›´èªªæ˜ |
|------|------|------|---------|
| 1.0 | 2026-02-17 | AI | åˆå§‹ç‰ˆæœ¬ |

---

**æ–‡ä»¶ç‹€æ…‹**ï¼šâœ… Draft Complete - å¾…å¯©æ ¸

**ä¸‹ä¸€æ­¥**ï¼šæ ¹æ“šæ­¤è¦æ ¼æ›¸é–‹å§‹é–‹ç™¼ `lib/ollama_helper.sh`
